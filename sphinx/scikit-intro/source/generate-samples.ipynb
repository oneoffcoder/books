{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (1000, 50), y shape (1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(**{\n",
    "    'n_samples': 1000, \n",
    "    'n_features': 50, \n",
    "    'n_informative': 10, \n",
    "    'n_targets': 1, \n",
    "    'bias': 5.3, \n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997115301602587"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X, y)\n",
    "\n",
    "explained_variance_score(y, lasso.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (2000, 20), y shape (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(**{\n",
    "    'n_samples': 2000, \n",
    "    'n_features': 20, \n",
    "    'n_informative': 2, \n",
    "    'n_redundant': 2, \n",
    "    'n_repeated': 0, \n",
    "    'n_classes': 2, \n",
    "    'n_clusters_per_class': 2, \n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9635284635284634"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=2)\n",
    "rf.fit(X, y)\n",
    "\n",
    "roc_auc_score(y, rf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (2000, 20), Y shape (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "X, Y = make_multilabel_classification(**{\n",
    "    'n_samples': 2000, \n",
    "    'n_features': 20, \n",
    "    'n_classes': 5, \n",
    "    'n_labels': 2, \n",
    "    'length': 50, \n",
    "    'allow_unlabeled': False, \n",
    "    'sparse': False, \n",
    "    'return_indicator': 'dense', \n",
    "    'return_distributions': False, \n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, Y shape {Y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8589404714735016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=2)\n",
    "rf.fit(X, Y)\n",
    "\n",
    "roc_auc_score(Y, rf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58750 : coverage_error\n",
      "0.93136 : label_ranking_average_precision_score\n",
      "0.09871 : label_ranking_loss\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import coverage_error, \\\n",
    "    label_ranking_average_precision_score, \\\n",
    "    label_ranking_loss\n",
    "\n",
    "probs = rf.predict_proba(X)\n",
    "n_cols = len(probs)\n",
    "n_rows = probs[0].shape[0]\n",
    "\n",
    "Y_preds = np.array([[probs[c][r][1] for c in range(n_cols)] for r in range(n_rows)])\n",
    "\n",
    "for metric in [coverage_error, label_ranking_average_precision_score, label_ranking_loss]:\n",
    "    print(f'{metric(Y, Y_preds):.5f} : {metric.__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (3000, 15), y shape (3000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(**{\n",
    "    'n_samples': 3000, \n",
    "    'n_features': 15, \n",
    "    'centers': 3, \n",
    "    'cluster_std': 1.0,\n",
    "    'center_box': (-10.0, 10.0),\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286949308825501"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "km = KMeans(n_clusters=3, random_state=37)\n",
    "km.fit(X)\n",
    "\n",
    "silhouette_score(X, km.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### California housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linnerud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "\n",
    "X, y = load_linnerud(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "\n",
    "T_X, T_y = fetch_20newsgroups_vectorized(subset='train', return_X_y=True)\n",
    "V_X, V_y = fetch_20newsgroups_vectorized(subset='test', return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ndownloader.figshare.com/files/5976039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "X, y = fetch_covtype(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KDD Cup 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ndownloader.figshare.com/files/5976042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "\n",
    "X, y = fetch_kddcup99(subset='http', return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RCV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://ndownloader.figshare.com/files/5976069\n",
      "Downloading https://ndownloader.figshare.com/files/5976066\n",
      "Downloading https://ndownloader.figshare.com/files/5976063\n",
      "Downloading https://ndownloader.figshare.com/files/5976060\n",
      "Downloading https://ndownloader.figshare.com/files/5976057\n",
      "Downloading https://ndownloader.figshare.com/files/5976048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "T_X, T_y = fetch_rcv1(subset='train', return_X_y=True)\n",
    "V_X, V_y = fetch_rcv1(subset='test', return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X, y = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Clara Higuera, Katheleen J. Gardiner, Krzysztof J. Cios  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression) - 2015   \n",
      "**Please cite**: Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126.\n",
      "\n",
      "Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.\n",
      "\n",
      "The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. \n",
      "\n",
      "The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. \n",
      "\n",
      "Classes: \n",
      "```\n",
      "* c-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \n",
      "* c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \n",
      "* c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \n",
      "* c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n",
      "* t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \n",
      "* t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n",
      "* t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n",
      "* t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) \n",
      "```\n",
      "\n",
      "The aim is to identify subsets of proteins that are discriminant between the classes. \n",
      "\n",
      "### Attribute Information:\n",
      "\n",
      "```\n",
      "1 Mouse ID \n",
      "2..78 Values of expression levels of 77 proteins; the names of proteins are followed by &acirc;&euro;&oelig;_n&acirc;&euro; indicating that they were measured in the nuclear fraction. For example: DYRK1A_n \n",
      "79 Genotype: control (c) or trisomy (t) \n",
      "80 Treatment type: memantine (m) or saline (s) \n",
      "81 Behavior: context-shock (CS) or shock-context (SC) \n",
      "82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m \n",
      "```\n",
      "\n",
      "### Relevant Papers:\n",
      "\n",
      "Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126 \n",
      "\n",
      "Ahmed MM, Dhanasekaran AR, Block A, Tong S, Costa ACS, Stasko M, et al. (2015) Protein Dynamics Associated with Failed and Rescued Learning in the Ts65Dn Mouse Model of Down Syndrome. PLoS ONE 10(3): e0119491.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mice = fetch_openml(name='miceprotein', version=4)\n",
    "X, y = mice.data, mice.target\n",
    "\n",
    "print(mice.DESCR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
