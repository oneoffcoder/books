{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training shape=(1600, 20), y training shape=(1600,)\n",
      "X validation shape=(400, 20), y validation shape=(1600,)\n",
      "X training missing data points 80\n",
      "X validation missing data points 20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "\n",
    "def get_data(n_features=20, n_samples=2000, n_missing=100):\n",
    "    def generate_coordinates(m, n):\n",
    "        seen = set()\n",
    "\n",
    "        x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "\n",
    "        while True:\n",
    "            seen.add((x, y))\n",
    "            yield (x, y)\n",
    "            x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "            while (x, y) in seen:\n",
    "                x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "                \n",
    "    def make_missing(X):\n",
    "        coords = generate_coordinates(n_samples, n_features)\n",
    "    \n",
    "        for _ in range(n_missing):\n",
    "            i, j = next(coords)\n",
    "            X[i][j] = np.nan\n",
    "            \n",
    "    def split(X, y):\n",
    "        splitter = ShuffleSplit(n_splits=1, test_size=0.2, train_size=0.8, random_state=37)\n",
    "        train_index, test_index = next(splitter.split(X, y))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    X, y = make_regression(**{\n",
    "        'n_samples': n_samples, \n",
    "        'n_features': n_features, \n",
    "        'n_informative': 10, \n",
    "        'n_targets': 1, \n",
    "        'bias': 5.3, \n",
    "        'random_state': 37\n",
    "    })\n",
    "    \n",
    "    make_missing(X)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = split(X, y)\n",
    "    return Data(X_train, y_train), Data(X_test, y_test)\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "# to verify missing data\n",
    "T, V = get_data()\n",
    "\n",
    "print(f'X training shape={T.X.shape}, y training shape={T.y.shape}')\n",
    "print(f'X validation shape={V.X.shape}, y validation shape={T.y.shape}')\n",
    "\n",
    "print(f'X training missing data points {np.count_nonzero(np.isnan(T.X))}')\n",
    "print(f'X validation missing data points {np.count_nonzero(np.isnan(V.X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99609: r-squared\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "imputer = IterativeImputer(missing_values=np.nan, random_state=37)\n",
    "scaler = StandardScaler()\n",
    "lasso = Lasso()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler), \n",
    "    ('lasso', lasso)\n",
    "])\n",
    "\n",
    "pipeline.fit(T.X, T.y)\n",
    "y_preds = pipeline.predict(V.X)\n",
    "\n",
    "print(f'{r2_score(V.y, y_preds):.5f}: r-squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "\n",
    "def get_data(n_features=20, n_samples=2000, n_missing=100):\n",
    "    def generate_coordinates(m, n):\n",
    "        seen = set()\n",
    "\n",
    "        x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "\n",
    "        while True:\n",
    "            seen.add((x, y))\n",
    "            yield (x, y)\n",
    "            x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "            while (x, y) in seen:\n",
    "                x, y = randint(0, m - 1), randint(0, n - 1)\n",
    "                \n",
    "    def make_missing(X):\n",
    "        coords = generate_coordinates(n_samples, n_features)\n",
    "    \n",
    "        for _ in range(n_missing):\n",
    "            i, j = next(coords)\n",
    "            X[i][j] = np.nan\n",
    "            \n",
    "    def split(X, y):\n",
    "        splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=37)\n",
    "        train_index, test_index = next(splitter.split(X, y))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    X, y = make_classification(**{\n",
    "        'n_samples': n_samples, \n",
    "        'n_features': n_features, \n",
    "        'n_informative': 2, \n",
    "        'n_redundant': 2, \n",
    "        'n_repeated': 0, \n",
    "        'n_classes': 2, \n",
    "        'n_clusters_per_class': 2, \n",
    "        'random_state': 37\n",
    "    })\n",
    "    \n",
    "    make_missing(X)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = split(X, y)\n",
    "    return Data(X_train, y_train), Data(X_test, y_test)\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "# to verify missing data\n",
    "T, V = get_data()\n",
    "\n",
    "print(f'X training shape={T.X.shape}, y training shape={T.y.shape}')\n",
    "print(f'X validation shape={V.X.shape}, y validation shape={T.y.shape}')\n",
    "\n",
    "print(f'X training missing data points {np.count_nonzero(np.isnan(T.X))}')\n",
    "print(f'X validation missing data points {np.count_nonzero(np.isnan(V.X))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "imputer = IterativeImputer(missing_values=np.nan, random_state=37)\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=3, random_state=37)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler), \n",
    "    ('pca', pca),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "pipeline.fit(T.X, T.y)\n",
    "y_preds = pipeline.predict_proba(V.X)[:,1]\n",
    "\n",
    "print(f'{roc_auc_score(V.y, y_preds):.5f}: ROC AUC')\n",
    "print(f'{average_precision_score(V.y, y_preds):.5f}: PR AUC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
