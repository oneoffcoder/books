{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal\n",
    "from scipy.stats import binom\n",
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "def get_data(N=10000, M=10):\n",
    "    X = np.hstack([normal(0.0, 1.0, N).reshape(N, 1) for _ in range(M)])\n",
    "    \n",
    "    w = np.array([w + 1.0 for w in range(M)])\n",
    "    z = np.dot(X, w) + normal(0.0, 0.2, N)\n",
    "    p = 1.0 / (1.0 + np.exp(-z))\n",
    "    y = binom.rvs(1, p)\n",
    "    \n",
    "    return Data(X, y)\n",
    "\n",
    "# training\n",
    "T = get_data()\n",
    "\n",
    "# validation\n",
    "V = get_data(N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=False)\n",
    "lr.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                              store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network, Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000, alpha=0.01)\n",
    "mlp.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, probability=True, random_state=37, shrinking=True,\n",
       "      tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "svm = NuSVC(gamma='auto', probability=True, random_state=37)\n",
    "svm.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descient (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss='log')\n",
    "sgd.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>brier_score_loss</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>hinge_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>average_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.976842</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.956086</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.054495</td>\n",
       "      <td>0.569966</td>\n",
       "      <td>0.998527</td>\n",
       "      <td>0.998359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.966030</td>\n",
       "      <td>0.934292</td>\n",
       "      <td>0.935792</td>\n",
       "      <td>0.079076</td>\n",
       "      <td>0.294971</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>0.997130</td>\n",
       "      <td>0.996774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969442</td>\n",
       "      <td>0.940695</td>\n",
       "      <td>0.942007</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.149966</td>\n",
       "      <td>0.653551</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>0.998193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.976842</td>\n",
       "      <td>0.954733</td>\n",
       "      <td>0.956086</td>\n",
       "      <td>0.038260</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>0.653850</td>\n",
       "      <td>0.998246</td>\n",
       "      <td>0.998042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969506</td>\n",
       "      <td>0.940816</td>\n",
       "      <td>0.942097</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.062244</td>\n",
       "      <td>0.569476</td>\n",
       "      <td>0.997579</td>\n",
       "      <td>0.997283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.803797</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.627096</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>6.424290</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.813810</td>\n",
       "      <td>0.735136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.967334</td>\n",
       "      <td>0.936735</td>\n",
       "      <td>0.937996</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.067079</td>\n",
       "      <td>0.578227</td>\n",
       "      <td>0.997543</td>\n",
       "      <td>0.997283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.971307</td>\n",
       "      <td>0.944215</td>\n",
       "      <td>0.945813</td>\n",
       "      <td>0.018218</td>\n",
       "      <td>0.061125</td>\n",
       "      <td>0.576176</td>\n",
       "      <td>0.998270</td>\n",
       "      <td>0.998065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.921610</td>\n",
       "      <td>0.854617</td>\n",
       "      <td>0.851564</td>\n",
       "      <td>0.076666</td>\n",
       "      <td>0.271507</td>\n",
       "      <td>0.744460</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>0.978537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.916754</td>\n",
       "      <td>0.846304</td>\n",
       "      <td>0.841738</td>\n",
       "      <td>0.228336</td>\n",
       "      <td>0.649722</td>\n",
       "      <td>1.007489</td>\n",
       "      <td>0.979775</td>\n",
       "      <td>0.978109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  accuracy_score  f1_score  jaccard_score  \\\n",
       "0             LogisticRegression           0.978  0.976842       0.954733   \n",
       "1                     GaussianNB           0.968  0.966030       0.934292   \n",
       "2     LinearDiscriminantAnalysis           0.971  0.969442       0.940695   \n",
       "3  QuadraticDiscriminantAnalysis           0.978  0.976842       0.954733   \n",
       "4                  MLPClassifier           0.971  0.969506       0.940816   \n",
       "5         DecisionTreeClassifier           0.814  0.803797       0.671958   \n",
       "6                          NuSVC           0.969  0.967334       0.936735   \n",
       "7                  SGDClassifier           0.973  0.971307       0.944215   \n",
       "8         RandomForestClassifier           0.926  0.921610       0.854617   \n",
       "9             AdaBoostClassifier           0.921  0.916754       0.846304   \n",
       "\n",
       "   matthews_corrcoef  brier_score_loss  log_loss  hinge_loss  roc_auc_score  \\\n",
       "0           0.956086          0.016632  0.054495    0.569966       0.998527   \n",
       "1           0.935792          0.079076  0.294971    0.770754       0.997130   \n",
       "2           0.942007          0.038022  0.149966    0.653551       0.998378   \n",
       "3           0.956086          0.038260  0.150470    0.653850       0.998246   \n",
       "4           0.942097          0.019656  0.062244    0.569476       0.997579   \n",
       "5           0.627096          0.186000  6.424290    0.716000       0.813810   \n",
       "6           0.937996          0.020646  0.067079    0.578227       0.997543   \n",
       "7           0.945813          0.018218  0.061125    0.576176       0.998270   \n",
       "8           0.851564          0.076666  0.271507    0.744460       0.981208   \n",
       "9           0.841738          0.228336  0.649722    1.007489       0.979775   \n",
       "\n",
       "   average_precision_score  \n",
       "0                 0.998359  \n",
       "1                 0.996774  \n",
       "2                 0.998193  \n",
       "3                 0.998042  \n",
       "4                 0.997283  \n",
       "5                 0.735136  \n",
       "6                 0.997283  \n",
       "7                 0.998065  \n",
       "8                 0.978537  \n",
       "9                 0.978109  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, matthews_corrcoef, \\\n",
    "    precision_score, recall_score, \\\n",
    "    brier_score_loss, log_loss, hamming_loss, hinge_loss, zero_one_loss, \\\n",
    "    roc_auc_score, average_precision_score\n",
    "\n",
    "def get_scoring_functions():\n",
    "    cfuncs = [accuracy_score, f1_score, jaccard_score, matthews_corrcoef]\n",
    "    pfuncs = [brier_score_loss, log_loss, hinge_loss, \n",
    "              roc_auc_score, average_precision_score]\n",
    "    return cfuncs, pfuncs\n",
    "\n",
    "def get_tuple_cols():\n",
    "    cfuncs, pfuncs = get_scoring_functions()\n",
    "    return ['model'] + [f.__name__ for f in cfuncs] + [f.__name__ for f in pfuncs]\n",
    "    \n",
    "def get_scores(model_name, y_true, y_preds, y_probs):\n",
    "    cfuncs, pfuncs = get_scoring_functions()\n",
    "    \n",
    "    cscores = {f.__name__: f(y_true, y_preds) for f in cfuncs}\n",
    "    pscores = {f.__name__: f(y_true, y_probs) for f in pfuncs}\n",
    "    \n",
    "    d = {**cscores, **pscores}\n",
    "    d['model'] = model_name\n",
    "    \n",
    "    return tuple([d[c] for c in get_tuple_cols()])    \n",
    "    \n",
    "models = [lr, nb, lda, qda, mlp, dt, svm, sgd, rf, ab]\n",
    "model_names = [type(m).__name__ for m in models]\n",
    "\n",
    "y_preds = {type(model).__name__: model.predict(V.X) for model in models}\n",
    "y_probs = {type(model).__name__: model.predict_proba(V.X)[:,1] for model in models}\n",
    "\n",
    "scores = [get_scores(name, V.y, y_preds[name], y_probs[name]) for name in model_names]\n",
    "df = pd.DataFrame(scores, columns=get_tuple_cols())\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
