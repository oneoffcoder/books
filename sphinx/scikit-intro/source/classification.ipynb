{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import binomial, normal\n",
    "from scipy.stats import bernoulli, binom\n",
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "def get_data(N=10000, M=10):\n",
    "    X = np.hstack([normal(0.0, 1.0, N).reshape(N, 1) for _ in range(M)])\n",
    "    \n",
    "    w = np.array([w + 1.0 for w in range(M)])\n",
    "    z = np.dot(X, w) + normal(0.0, 0.2, N)\n",
    "    p = 1.0 / (1.0 + np.exp(-z))\n",
    "    y = binom.rvs(1, p)\n",
    "    \n",
    "    return Data(X, y)\n",
    "\n",
    "# training\n",
    "T = get_data()\n",
    "\n",
    "# validation\n",
    "V = get_data(N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=False)\n",
    "lr.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                              store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network, Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000, alpha=0.01)\n",
    "mlp.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
       "      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, probability=True, random_state=37, shrinking=True,\n",
       "      tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "svm = NuSVC(gamma='auto', probability=True, random_state=37)\n",
    "svm.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descient (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss='log')\n",
    "sgd.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(T.X, T.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"LogisticRegression\": {\n",
      "    \"accuracy_score\": 0.978,\n",
      "    \"f1_score\": 0.9768421052631578,\n",
      "    \"jaccard_score\": 0.9547325102880658,\n",
      "    \"matthews_corrcoef\": 0.9560863036789898,\n",
      "    \"brier_score_loss\": 0.016632172858407845,\n",
      "    \"log_loss\": 0.05449477427345123,\n",
      "    \"hinge_loss\": 0.5699658323409738,\n",
      "    \"roc_auc_score\": 0.9985266961059815,\n",
      "    \"average_precision_score\": 0.9983588702442507\n",
      "  },\n",
      "  \"GaussianNB\": {\n",
      "    \"accuracy_score\": 0.968,\n",
      "    \"f1_score\": 0.9660297239915074,\n",
      "    \"jaccard_score\": 0.9342915811088296,\n",
      "    \"matthews_corrcoef\": 0.9357917719570864,\n",
      "    \"brier_score_loss\": 0.07907594084643839,\n",
      "    \"log_loss\": 0.2949714231614986,\n",
      "    \"hinge_loss\": 0.7707541325687794,\n",
      "    \"roc_auc_score\": 0.9971296668004818,\n",
      "    \"average_precision_score\": 0.9967741788030196\n",
      "  },\n",
      "  \"LinearDiscriminantAnalysis\": {\n",
      "    \"accuracy_score\": 0.971,\n",
      "    \"f1_score\": 0.9694415173867228,\n",
      "    \"jaccard_score\": 0.9406952965235174,\n",
      "    \"matthews_corrcoef\": 0.9420068603929711,\n",
      "    \"brier_score_loss\": 0.038022049382832816,\n",
      "    \"log_loss\": 0.1499661041398179,\n",
      "    \"hinge_loss\": 0.6535512292466302,\n",
      "    \"roc_auc_score\": 0.9983781613809715,\n",
      "    \"average_precision_score\": 0.9981933072557339\n",
      "  },\n",
      "  \"QuadraticDiscriminantAnalysis\": {\n",
      "    \"accuracy_score\": 0.978,\n",
      "    \"f1_score\": 0.9768421052631578,\n",
      "    \"jaccard_score\": 0.9547325102880658,\n",
      "    \"matthews_corrcoef\": 0.9560863036789898,\n",
      "    \"brier_score_loss\": 0.03825985557756746,\n",
      "    \"log_loss\": 0.15047012014475764,\n",
      "    \"hinge_loss\": 0.6538504318500724,\n",
      "    \"roc_auc_score\": 0.9982456844640707,\n",
      "    \"average_precision_score\": 0.9980422705210839\n",
      "  },\n",
      "  \"MLPClassifier\": {\n",
      "    \"accuracy_score\": 0.971,\n",
      "    \"f1_score\": 0.9695057833859095,\n",
      "    \"jaccard_score\": 0.9408163265306122,\n",
      "    \"matthews_corrcoef\": 0.9420965161956771,\n",
      "    \"brier_score_loss\": 0.01965600244560319,\n",
      "    \"log_loss\": 0.06224368326321421,\n",
      "    \"hinge_loss\": 0.5694763823672737,\n",
      "    \"roc_auc_score\": 0.9975792854275392,\n",
      "    \"average_precision_score\": 0.9972829261476521\n",
      "  },\n",
      "  \"DecisionTreeClassifier\": {\n",
      "    \"accuracy_score\": 0.814,\n",
      "    \"f1_score\": 0.8037974683544303,\n",
      "    \"jaccard_score\": 0.671957671957672,\n",
      "    \"matthews_corrcoef\": 0.6270960194297263,\n",
      "    \"brier_score_loss\": 0.186,\n",
      "    \"log_loss\": 6.424289970404115,\n",
      "    \"hinge_loss\": 0.716,\n",
      "    \"roc_auc_score\": 0.8138097149739062,\n",
      "    \"average_precision_score\": 0.7351363838689575\n",
      "  },\n",
      "  \"NuSVC\": {\n",
      "    \"accuracy_score\": 0.969,\n",
      "    \"f1_score\": 0.9673340358271865,\n",
      "    \"jaccard_score\": 0.936734693877551,\n",
      "    \"matthews_corrcoef\": 0.9379961018440165,\n",
      "    \"brier_score_loss\": 0.02064565724996552,\n",
      "    \"log_loss\": 0.06707929411278822,\n",
      "    \"hinge_loss\": 0.5782268375064415,\n",
      "    \"roc_auc_score\": 0.9975431553592935,\n",
      "    \"average_precision_score\": 0.9972829926563956\n",
      "  },\n",
      "  \"SGDClassifier\": {\n",
      "    \"accuracy_score\": 0.973,\n",
      "    \"f1_score\": 0.9713071200850159,\n",
      "    \"jaccard_score\": 0.9442148760330579,\n",
      "    \"matthews_corrcoef\": 0.9458133286180086,\n",
      "    \"brier_score_loss\": 0.01821839579132532,\n",
      "    \"log_loss\": 0.06112492465796149,\n",
      "    \"hinge_loss\": 0.5761760581385446,\n",
      "    \"roc_auc_score\": 0.9982697711762345,\n",
      "    \"average_precision_score\": 0.9980645890771229\n",
      "  },\n",
      "  \"RandomForestClassifier\": {\n",
      "    \"accuracy_score\": 0.926,\n",
      "    \"f1_score\": 0.9216101694915254,\n",
      "    \"jaccard_score\": 0.8546168958742633,\n",
      "    \"matthews_corrcoef\": 0.8515642161356457,\n",
      "    \"brier_score_loss\": 0.076666,\n",
      "    \"log_loss\": 0.27150722412631356,\n",
      "    \"hinge_loss\": 0.74446,\n",
      "    \"roc_auc_score\": 0.9812083500602168,\n",
      "    \"average_precision_score\": 0.9785371928757163\n",
      "  },\n",
      "  \"AdaBoostClassifier\": {\n",
      "    \"accuracy_score\": 0.921,\n",
      "    \"f1_score\": 0.9167544783983139,\n",
      "    \"jaccard_score\": 0.8463035019455253,\n",
      "    \"matthews_corrcoef\": 0.8417378966691056,\n",
      "    \"brier_score_loss\": 0.2283355338755829,\n",
      "    \"log_loss\": 0.6497217061890992,\n",
      "    \"hinge_loss\": 1.0074894887955599,\n",
      "    \"roc_auc_score\": 0.9797751906864713,\n",
      "    \"average_precision_score\": 0.9781090429826292\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, matthews_corrcoef, \\\n",
    "    precision_score, recall_score, \\\n",
    "    brier_score_loss, log_loss, hamming_loss, hinge_loss, zero_one_loss, \\\n",
    "    roc_auc_score, average_precision_score\n",
    "\n",
    "def get_scores(y_true, y_preds, y_probs):\n",
    "    cfuncs = [accuracy_score, f1_score, jaccard_score, matthews_corrcoef]\n",
    "    pfuncs = [brier_score_loss, log_loss, hinge_loss, \n",
    "              roc_auc_score, average_precision_score]\n",
    "    \n",
    "    cscores = {f.__name__: f(y_true, y_preds) for f in cfuncs}\n",
    "    pscores = {f.__name__: f(y_true, y_probs) for f in pfuncs}\n",
    "    \n",
    "    return {**cscores, **pscores}\n",
    "    \n",
    "models = [lr, nb, lda, qda, mlp, dt, svm, sgd, rf, ab]\n",
    "model_names = [type(m).__name__ for m in models]\n",
    "\n",
    "y_preds = {type(model).__name__: model.predict(V.X) for model in models}\n",
    "y_probs = {type(model).__name__: model.predict_proba(V.X)[:,1] for model in models}\n",
    "\n",
    "scores = {name: get_scores(V.y, y_preds[name], y_probs[name]) for name in model_names}\n",
    "\n",
    "print(json.dumps(scores, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
