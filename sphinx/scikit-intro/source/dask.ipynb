{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "`Dask` is a parallel processing API that has analogous data structures to `numpy` arrays, `pandas` dataframes and `Spark` RDDs. In the cases of arrays and dataframes, unlike their original data structures in numpy and pandas, the `Dask` versions are distributed and operations are parallelized. The `bag` data structure of dask is the analog to a Spark RDD, and both are distributed data structures. These distributed data structures are called `high-level collections` in Dask.\n",
    "\n",
    "| Dask Analog | Existing Data Structures |\n",
    "| --- | ----------- |\n",
    "| Array | Numpy Array |\n",
    "| DataFrame | Pandas DataFrame |\n",
    "| Bag | Spark RDD |\n",
    "\n",
    "Dask seems to take the best of what's fundamental and available to the Python data science toolset and unifies them into a single framework. If you have ever worked with [Apache Spark](https://spark.apache.org/) and seen its web interface, Dask has a similar dashboard (runs on port `8787` by default). Like Spark, Dask is also built on the concept of a `driver` submitting jobs (centered on a distributed data structure) to a `cluster` of workers. Here's a more in depth [comparison and contrast](https://docs.dask.org/en/latest/spark.html) of Dask and Spark. Let's take glance at dask and see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster and client\n",
    "\n",
    "In Dask, the `Client` represents the `driver` and the `LocalCluster` represents the `cluster`. The driver controls the manipulation of distributed data through submission of jobs to the cluster. The `LocalCluster` is not a real cluster of separate, physical worker nodes, but it mimics one and is useful for local development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:27:32.997361Z",
     "iopub.status.busy": "2020-12-16T07:27:32.997361Z",
     "iopub.status.idle": "2020-12-16T07:27:37.529356Z",
     "shell.execute_reply": "2020-12-16T07:27:37.528360Z",
     "shell.execute_reply.started": "2020-12-16T07:27:32.997361Z"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "params = {\n",
    "    'n_workers': 4,\n",
    "    'threads_per_worker': 2,\n",
    "    'dashboard_address': '8787'\n",
    "}\n",
    "cluster = LocalCluster(**params)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:27:42.302361Z",
     "iopub.status.busy": "2020-12-16T07:27:42.302361Z",
     "iopub.status.idle": "2020-12-16T07:27:42.327357Z",
     "shell.execute_reply": "2020-12-16T07:27:42.326359Z",
     "shell.execute_reply.started": "2020-12-16T07:27:42.302361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59227</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>25.76 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59227' processes=4 threads=8, memory=25.76 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A Dask [DataFrame](https://docs.dask.org/en/latest/dataframe-api.html) behaves nearly identical to a pandas one. There's a couple of ways to create a Dask DataFrame (e.g. reading from files), but, here, we create a Pandas one and use the `from_pandas()` function to convert the Pandas DataFrame to a Dask one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T08:05:54.320554Z",
     "iopub.status.busy": "2020-12-16T08:05:54.320554Z",
     "iopub.status.idle": "2020-12-16T08:05:54.341553Z",
     "shell.execute_reply": "2020-12-16T08:05:54.340555Z",
     "shell.execute_reply.started": "2020-12-16T08:05:54.320554Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "np.random.seed(37)\n",
    "random.seed(37)\n",
    "\n",
    "def to_pdf(X, y):\n",
    "    A = pd.DataFrame(X, columns=[f'x{i}' for i in range(X.shape[1])])\n",
    "    b = pd.DataFrame(pd.Series(y, name='y'))\n",
    "    return A, b\n",
    "\n",
    "def to_seq(X, y):\n",
    "    A = [{c: r[c] for c in X.columns} for _, r in X.iterrows()]\n",
    "    b = [{c: r[c] for c in y.columns} for _, r in y.iterrows()]\n",
    "    return A, b\n",
    "\n",
    "def get_regression(n_samples=2000):\n",
    "    X, y = make_regression(**{\n",
    "        'n_samples': n_samples,\n",
    "        'n_features': 10,\n",
    "        'n_informative': 5,\n",
    "        'n_targets': 1,\n",
    "        'bias': 5.3,\n",
    "        'random_state': 37\n",
    "    })\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_classification(n_samples=2000):\n",
    "    X, y = make_classification(**{\n",
    "        'n_samples': n_samples,\n",
    "        'n_features': 10,\n",
    "        'n_informative': 5,\n",
    "        'n_redundant': 2,\n",
    "        'n_repeated': 0,\n",
    "        'n_classes': 2,\n",
    "        'n_clusters_per_class': 2,\n",
    "        'random_state': 37\n",
    "    })\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = get_regression()\n",
    "X, y = to_pdf(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Spark, we have to worry about the number of partitions in Dask as well. For now, we will specify 100 arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:41:31.025567Z",
     "iopub.status.busy": "2020-12-16T07:41:31.024568Z",
     "iopub.status.idle": "2020-12-16T07:41:31.046568Z",
     "shell.execute_reply": "2020-12-16T07:41:31.044569Z",
     "shell.execute_reply.started": "2020-12-16T07:41:31.025567Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "X = dd.from_pandas(X, npartitions=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to get the string representation of a Dask DataFrame, notice how the actual data is not displayed, but, rather, just some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:35:59.269080Z",
     "iopub.status.busy": "2020-12-16T07:35:59.269080Z",
     "iopub.status.idle": "2020-12-16T07:35:59.305078Z",
     "shell.execute_reply": "2020-12-16T07:35:59.303082Z",
     "shell.execute_reply.started": "2020-12-16T07:35:59.269080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=100</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 100 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                      x0       x1       x2       x3       x4       x5       x6       x7       x8       x9\n",
       "npartitions=100                                                                                          \n",
       "0                float64  float64  float64  float64  float64  float64  float64  float64  float64  float64\n",
       "20                   ...      ...      ...      ...      ...      ...      ...      ...      ...      ...\n",
       "...                  ...      ...      ...      ...      ...      ...      ...      ...      ...      ...\n",
       "1980                 ...      ...      ...      ...      ...      ...      ...      ...      ...      ...\n",
       "1999                 ...      ...      ...      ...      ...      ...      ...      ...      ...      ...\n",
       "Dask Name: from_pandas, 100 tasks"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:36:01.944084Z",
     "iopub.status.busy": "2020-12-16T07:36:01.943078Z",
     "iopub.status.idle": "2020-12-16T07:36:01.966087Z",
     "shell.execute_reply": "2020-12-16T07:36:01.965080Z",
     "shell.execute_reply.started": "2020-12-16T07:36:01.944084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0    float64\n",
       "x1    float64\n",
       "x2    float64\n",
       "x3    float64\n",
       "x4    float64\n",
       "x5    float64\n",
       "x6    float64\n",
       "x7    float64\n",
       "x8    float64\n",
       "x9    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can invoke statistical functions like `sum()`, `mean()` and `std()` on the DataFrame. However, if we want the results to come back to the client, we need to issue `compute()`. This pattern of functions mimics Spark's `transformation` vs `action` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:36:04.511082Z",
     "iopub.status.busy": "2020-12-16T07:36:04.511082Z",
     "iopub.status.idle": "2020-12-16T07:36:06.044081Z",
     "shell.execute_reply": "2020-12-16T07:36:06.042080Z",
     "shell.execute_reply.started": "2020-12-16T07:36:04.511082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0     8.309788\n",
       "x1    -7.660057\n",
       "x2    -1.745221\n",
       "x3    -8.071736\n",
       "x4   -25.665312\n",
       "x5    70.528265\n",
       "x6   -18.859073\n",
       "x7   -15.195804\n",
       "x8   -46.170896\n",
       "x9   -29.945949\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:36:20.634082Z",
     "iopub.status.busy": "2020-12-16T07:36:20.634082Z",
     "iopub.status.idle": "2020-12-16T07:36:21.379106Z",
     "shell.execute_reply": "2020-12-16T07:36:21.377082Z",
     "shell.execute_reply.started": "2020-12-16T07:36:20.634082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0    0.004155\n",
       "x1   -0.003830\n",
       "x2   -0.000873\n",
       "x3   -0.004036\n",
       "x4   -0.012833\n",
       "x5    0.035264\n",
       "x6   -0.009430\n",
       "x7   -0.007598\n",
       "x8   -0.023085\n",
       "x9   -0.014973\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:36:33.501077Z",
     "iopub.status.busy": "2020-12-16T07:36:33.500078Z",
     "iopub.status.idle": "2020-12-16T07:36:34.138078Z",
     "shell.execute_reply": "2020-12-16T07:36:34.136076Z",
     "shell.execute_reply.started": "2020-12-16T07:36:33.501077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0    0.984805\n",
       "x1    1.004140\n",
       "x2    1.014151\n",
       "x3    1.016681\n",
       "x4    0.982926\n",
       "x5    0.981421\n",
       "x6    0.986267\n",
       "x7    1.025351\n",
       "x8    1.019498\n",
       "x9    0.986211\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.std().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag\n",
    "\n",
    "Dask [Bags](https://docs.dask.org/en/latest/bag-api.html) are like Spark RDDs. You get similar functions to RDDs with Bags like `map()`, `filter()` and `reduce()`. The `reduceByKey()` in Spark RDDs is `foldby()` in Dask Bags. The `reduce()` in Spark RDDs is `fold()` in Dask Bags. \n",
    "\n",
    "Below, to create a Dask Bag, we use `from_sequence()` where our collection has dictionary elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:53:56.306819Z",
     "iopub.status.busy": "2020-12-16T07:53:56.306819Z",
     "iopub.status.idle": "2020-12-16T07:53:57.232818Z",
     "shell.execute_reply": "2020-12-16T07:53:57.231822Z",
     "shell.execute_reply.started": "2020-12-16T07:53:56.306819Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "X, y = get_regression()\n",
    "X, y = to_pdf(X, y)\n",
    "X, y = to_seq(X, y)\n",
    "X = db.from_sequence(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of map and reduce by key. In the map operation, we map a dictionary element to a tuple, where the first element is a boolean indicating if the integer representation of the `x0` field is even, and the second element is the value of `x0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:53:57.234822Z",
     "iopub.status.busy": "2020-12-16T07:53:57.234822Z",
     "iopub.status.idle": "2020-12-16T07:53:58.059820Z",
     "shell.execute_reply": "2020-12-16T07:53:58.058823Z",
     "shell.execute_reply.started": "2020-12-16T07:53:57.234822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True, (True, -7.959470449062381)), (False, (False, 16.269258267363348))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.map(lambda r: (int(r['x0']) % 2 == 0, r['x0']))\n",
    " .foldby(lambda tup: tup[0], lambda a, b: (a[0], a[1] + b[1]))\n",
    " .compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we filter for even numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:53:58.062823Z",
     "iopub.status.busy": "2020-12-16T07:53:58.062823Z",
     "iopub.status.idle": "2020-12-16T07:53:58.681817Z",
     "shell.execute_reply": "2020-12-16T07:53:58.678819Z",
     "shell.execute_reply.started": "2020-12-16T07:53:58.062823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True, (True, -7.959470449062381))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.map(lambda r: (int(r['x0']) % 2 == 0, r['x0']))\n",
    " .filter(lambda tup: tup[0])\n",
    " .foldby(lambda tup: tup[0], lambda a, b: (a[0], a[1] + b[1]))\n",
    " .compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exampke, we filter for odd numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:53:58.903822Z",
     "iopub.status.busy": "2020-12-16T07:53:58.903822Z",
     "iopub.status.idle": "2020-12-16T07:53:59.585822Z",
     "shell.execute_reply": "2020-12-16T07:53:59.583822Z",
     "shell.execute_reply.started": "2020-12-16T07:53:58.903822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, (False, 16.269258267363348))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.map(lambda r: (int(r['x0']) % 2 == 0, r['x0']))\n",
    " .filter(lambda tup: not tup[0])\n",
    " .foldby(lambda tup: tup[0], lambda a, b: (a[0], a[1] + b[1]))\n",
    " .compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T07:53:59.588820Z",
     "iopub.status.busy": "2020-12-16T07:53:59.587828Z",
     "iopub.status.idle": "2020-12-16T07:54:00.159822Z",
     "shell.execute_reply": "2020-12-16T07:54:00.158822Z",
     "shell.execute_reply.started": "2020-12-16T07:53:59.588820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.959470449062381"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.map(lambda r: r['x0'])\n",
    " .filter(lambda x0: int(x0) % 2 == 0)\n",
    " .fold(lambda a, b: a + b)\n",
    " .compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "A Dask DataFrame can be used as a drop-in replacement for a pandas DataFrame. Here, we use the Dask DataFrames as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T08:08:34.043613Z",
     "iopub.status.busy": "2020-12-16T08:08:34.043613Z",
     "iopub.status.idle": "2020-12-16T08:08:34.138611Z",
     "shell.execute_reply": "2020-12-16T08:08:34.136614Z",
     "shell.execute_reply.started": "2020-12-16T08:08:34.043613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('intercept', -0.4096500455402346),\n",
       " ('x0', 0.05472569830192885),\n",
       " ('x1', -0.3576951243307095),\n",
       " ('x2', -0.016887091414339032),\n",
       " ('x3', 0.9748572795615676),\n",
       " ('x4', 0.3314410250166681),\n",
       " ('x5', 0.7442808664015453),\n",
       " ('x6', 0.0035693089244456795),\n",
       " ('x7', 0.09115568775512932),\n",
       " ('x8', 0.08237183854292032),\n",
       " ('x9', -0.1556104235780201)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = get_classification()\n",
    "X, y = to_pdf(X, y)\n",
    "\n",
    "model = LogisticRegression(random_state=37, penalty='none', verbose=10)\n",
    "model.fit(X, y)\n",
    "[('intercept', model.intercept_[0])] + [(f, c) for f, c in zip(X.columns, model.coef_[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T08:09:05.631613Z",
     "iopub.status.busy": "2020-12-16T08:09:05.631613Z",
     "iopub.status.idle": "2020-12-16T08:09:05.664618Z",
     "shell.execute_reply": "2020-12-16T08:09:05.662611Z",
     "shell.execute_reply.started": "2020-12-16T08:09:05.631613Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-75018a84eb18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdask_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dask_ml'"
     ]
    }
   ],
   "source": [
    "from dask_ml.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
