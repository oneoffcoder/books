{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Scikit has many approaches to optimizing or tuning the hyperparameters of models. Let's take a look at how we can use `GridSearchCV` to search over a space of possible hyperparamter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data\n",
    "\n",
    "Let's create a dummy binary classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (2000, 20), y shape (2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "X, y = make_classification(**{\n",
    "    'n_samples': 2000,\n",
    "    'n_features': 20,\n",
    "    'n_informative': 2,\n",
    "    'n_redundant': 2,\n",
    "    'n_repeated': 0,\n",
    "    'n_classes': 2,\n",
    "    'n_clusters_per_class': 2,\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression\n",
    "\n",
    "Let's try to tune a logistic regression model. The logistic regression model will be referred to as the `estimator`; it is this estimator's possible hyperparamters that we want to optimize. When tuning hyperparameters, we also need a way to split the data, and here, we will use `StratifiedKFold`. Another important input to the grid search is the `param_grid` argument, which is a dictionary specifying the search space of each hyperparameter. Here, our search space is simple, it is over the `regularization strength`. Lastly, we need an optimization criteria, and we specify that through the [scoring argument](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  55 | elapsed:    1.0s remaining:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  55 | elapsed:    1.0s remaining:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  55 | elapsed:    1.1s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  55 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=37, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=37, solver='sag'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                               0.9, 1.0]},\n",
       "             refit='auc',\n",
       "             scoring={'apr': 'average_precision', 'auc': 'roc_auc'}, verbose=5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "p = {\n",
    "    'solver': 'sag',\n",
    "    'penalty': 'l2',\n",
    "    'random_state': 37,\n",
    "    'max_iter': 100\n",
    "}\n",
    "estimator = LogisticRegression(**p)\n",
    "\n",
    "p = {\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 37\n",
    "}\n",
    "cv = StratifiedKFold(**p)\n",
    "\n",
    "p = {\n",
    "    'estimator': estimator,\n",
    "    'cv': cv,\n",
    "    'param_grid': {\n",
    "        'C': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'scoring': {\n",
    "        'auc': 'roc_auc',\n",
    "        'apr': 'average_precision'\n",
    "    },\n",
    "    'verbose': 5,\n",
    "    'refit': 'auc',\n",
    "    'error_score': np.NaN,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "model = GridSearchCV(**p)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `best_params_` property gives the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `best_score_` property gives the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644498503712592"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the best estimator induced by the search and scoring criteria, access `best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.4, random_state=37, solver='sag')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Random Forest\n",
    "\n",
    "Here, we tune a `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of 100 | elapsed:    0.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of 100 | elapsed:    0.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=37, shuffle=True),\n",
       "             estimator=RandomForestClassifier(random_state=37), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100]},\n",
       "             refit='auc',\n",
       "             scoring={'apr': 'average_precision', 'auc': 'roc_auc'}, verbose=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "p = {\n",
    "    'random_state': 37\n",
    "}\n",
    "estimator = RandomForestClassifier(**p)\n",
    "\n",
    "p = {\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 37\n",
    "}\n",
    "cv = StratifiedKFold(**p)\n",
    "\n",
    "p = {\n",
    "    'estimator': estimator,\n",
    "    'cv': cv,\n",
    "    'param_grid': {\n",
    "        'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'scoring': {\n",
    "        'auc': 'roc_auc',\n",
    "        'apr': 'average_precision'\n",
    "    },\n",
    "    'verbose': 5,\n",
    "    'refit': 'auc',\n",
    "    'error_score': np.NaN,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "model = GridSearchCV(**p)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'n_estimators': 50}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763199132478311"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=50, random_state=37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning with a pipeline\n",
    "\n",
    "Our estimator can also be a pipeline. For each processor in the pipeline, we can also specify the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 708 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=37, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('pca', PCA()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=37))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'pca__n_components': [2, 3, 4, 5, 10, 11, 12, 15],\n",
       "                         'rf__criterion': ['gini', 'entropy'],\n",
       "                         'rf__n_estimators': [10, 20, 30, 40, 50, 60, 70, 80,\n",
       "                                              90, 100],\n",
       "                         'scaler__feature_range': [(0, 1), (0, 2)]},\n",
       "             refit='auc',\n",
       "             scoring={'apr': 'average_precision', 'auc': 'roc_auc'}, verbose=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA()\n",
    "rf = RandomForestClassifier(**{\n",
    "    'random_state': 37\n",
    "})\n",
    "pipeline = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('rf', rf)])\n",
    "\n",
    "cv = StratifiedKFold(**{\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "model = GridSearchCV(**{\n",
    "    'estimator': pipeline,\n",
    "    'cv': cv,\n",
    "    'param_grid': {\n",
    "        'scaler__feature_range': [(0, 1), (0, 2)],\n",
    "        'pca__n_components': [2, 3, 4, 5, 10, 11, 12, 15],\n",
    "        'rf__n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'rf__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'scoring': {\n",
    "        'auc': 'roc_auc',\n",
    "        'apr': 'average_precision'\n",
    "    },\n",
    "    'verbose': 5,\n",
    "    'refit': 'auc',\n",
    "    'error_score': np.NaN,\n",
    "    'n_jobs': -1\n",
    "})\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 3,\n",
       " 'rf__criterion': 'entropy',\n",
       " 'rf__n_estimators': 70,\n",
       " 'scaler__feature_range': (0, 1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710898858096453"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('pca', PCA(n_components=3)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(criterion='entropy', n_estimators=70,\n",
       "                                        random_state=37))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation with tuning\n",
    "\n",
    "In some cases, you might want to validate the hyperparameter tuning as a part of your learning process. In this example, we show an example of how to so. Here are some things to note in this example.\n",
    "\n",
    "- The data generated will be multiclass.\n",
    "- We will implement custom scorers. The average precision score does not natively handle the multi-class label, and we will have to transform the ground truth lables into a one-hot encoded vector.\n",
    "\n",
    "Now let's generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (1000, 10), y shape (1000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(**{\n",
    "    'n_samples': 1000,\n",
    "    'n_features': 10,\n",
    "    'n_clusters_per_class': 1,\n",
    "    'n_classes': 3,\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "print(f'X shape = {X.shape}, y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a `model` that is a grid search based on random forest. Note how we use the `make_scorer()` method to create custom scorers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def apr_score(y_true, y_pred, average='micro'):\n",
    "    encoder = OneHotEncoder()\n",
    "    Y = encoder.fit_transform(y_true.reshape(-1, 1)).todense()\n",
    "    \n",
    "    return average_precision_score(Y, y_pred, average=average)\n",
    "\n",
    "def get_model():\n",
    "    scaler = MinMaxScaler()\n",
    "    pca = PCA()\n",
    "    rf = RandomForestClassifier(**{\n",
    "        'random_state': 37\n",
    "    })\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('rf', rf)])\n",
    "\n",
    "    cv = StratifiedKFold(**{\n",
    "        'n_splits': 5,\n",
    "        'shuffle': True,\n",
    "        'random_state': 37\n",
    "    })\n",
    "    \n",
    "    auc_scorer = make_scorer(\n",
    "        roc_auc_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        multi_class='ovo')\n",
    "    apr_scorer_macro = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='macro')\n",
    "    apr_scorer_micro = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='micro')\n",
    "    apr_scorer_weighted = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='weighted')\n",
    "\n",
    "    model = GridSearchCV(**{\n",
    "        'estimator': pipeline,\n",
    "        'cv': cv,\n",
    "        'param_grid': {\n",
    "            'scaler__feature_range': [(0, 1), (0, 2)],\n",
    "            'pca__n_components': [2, 3, 4, 5, 10, 11, 12, 15],\n",
    "            'rf__n_estimators': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "            'rf__criterion': ['gini', 'entropy']\n",
    "        },\n",
    "        'scoring': {\n",
    "            'auc': auc_scorer,\n",
    "            'apr_scorer_macro': apr_scorer_macro,\n",
    "            'apr_scorer_micro': apr_scorer_micro,\n",
    "            'apr_scorer_weighted': apr_scorer_weighted\n",
    "        },\n",
    "        'verbose': 5,\n",
    "        'refit': 'apr_scorer_micro',\n",
    "        'error_score': np.NaN,\n",
    "        'n_jobs': -1\n",
    "    })\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform stratified, k-fold cross-validation while incorporating hyperparameter tuning as a part of the validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1972 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 704 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2240 out of 2240 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "results = []\n",
    "\n",
    "for tr, te in StratifiedKFold(random_state=37, shuffle=True, n_splits=10).split(X, y):\n",
    "    X_tr, X_te = X[tr], X[te]\n",
    "    y_tr, y_te = y[tr], y[te]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_te)\n",
    "    \n",
    "    auc_ovr = roc_auc_score(y_te, y_pred, multi_class='ovr')\n",
    "    auc_ovo = roc_auc_score(y_te, y_pred, multi_class='ovo')\n",
    "    apr_macro = apr_score(y_te, y_pred, average='macro')\n",
    "    apr_micro = apr_score(y_te, y_pred, average='micro')\n",
    "    apr_weighted = apr_score(y_te, y_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'auc_ovr': auc_ovr,\n",
    "        'auc_ovo': auc_ovo,\n",
    "        'apr_macro': apr_macro,\n",
    "        'apr_micro': apr_micro,\n",
    "        'apr_weighted': apr_weighted\n",
    "    })\n",
    "    \n",
    "rdf = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_ovr         0.998931\n",
       "auc_ovo         0.998932\n",
       "apr_macro       0.997529\n",
       "apr_micro       0.997535\n",
       "apr_weighted    0.997533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune-sklearn\n",
    "\n",
    "[tune-sklearn](https://github.com/ray-project/tune-sklearn) is a drop-in replacement for scikit-learn's hyperparameter tuning. This API promises to find hyperpameters in a shorter amount of time and smarter way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tune_sklearn import TuneGridSearchCV\n",
    "\n",
    "def get_model():\n",
    "    scaler = MinMaxScaler()\n",
    "    pca = PCA()\n",
    "    rf = RandomForestClassifier(**{\n",
    "        'random_state': 37\n",
    "    })\n",
    "    pipeline = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('rf', rf)])\n",
    "\n",
    "    cv = StratifiedKFold(**{\n",
    "        'n_splits': 5,\n",
    "        'shuffle': True,\n",
    "        'random_state': 37\n",
    "    })\n",
    "    \n",
    "    auc_scorer = make_scorer(\n",
    "        roc_auc_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        multi_class='ovo')\n",
    "    apr_scorer_macro = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='macro')\n",
    "    apr_scorer_micro = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='micro')\n",
    "    apr_scorer_weighted = make_scorer(\n",
    "        apr_score, \n",
    "        greater_is_better=True, \n",
    "        needs_proba=True, \n",
    "        average='weighted')\n",
    "\n",
    "    model = TuneGridSearchCV(**{\n",
    "        'estimator': pipeline,\n",
    "        'cv': cv,\n",
    "        'param_grid': {\n",
    "            'scaler__feature_range': [(0, 1)],\n",
    "            'pca__n_components': [2, 3, 4, 5],\n",
    "            'rf__criterion': ['gini', 'entropy']\n",
    "        },\n",
    "        'scoring': {\n",
    "            'auc': auc_scorer,\n",
    "            'apr_scorer_macro': apr_scorer_macro,\n",
    "            'apr_scorer_micro': apr_scorer_micro,\n",
    "            'apr_scorer_weighted': apr_scorer_weighted\n",
    "        },\n",
    "        'verbose': 1,\n",
    "        'refit': 'apr_scorer_micro',\n",
    "        'error_score': np.NaN,\n",
    "        'n_jobs': -1,\n",
    "        'early_stopping': 'MedianStoppingRule',\n",
    "        'max_iters': 10\n",
    "    })\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.3/50.1 GiB<br>Using MedianStoppingRule: num_stopped=0.<br>Resources requested: 0/32 CPUs, 0/0 GPUs, 0.0/28.61 GiB heap, 0.0/9.86 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-05-07_13-29-16<br>Number of trials: 8/8 (8 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for tr, te in StratifiedKFold(random_state=37, shuffle=True, n_splits=5).split(X, y):\n",
    "    X_tr, X_te = X[tr], X[te]\n",
    "    y_tr, y_te = y[tr], y[te]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_te)\n",
    "    \n",
    "    auc_ovr = roc_auc_score(y_te, y_pred, multi_class='ovr')\n",
    "    auc_ovo = roc_auc_score(y_te, y_pred, multi_class='ovo')\n",
    "    apr_macro = apr_score(y_te, y_pred, average='macro')\n",
    "    apr_micro = apr_score(y_te, y_pred, average='micro')\n",
    "    apr_weighted = apr_score(y_te, y_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'auc_ovr': auc_ovr,\n",
    "        'auc_ovo': auc_ovo,\n",
    "        'apr_macro': apr_macro,\n",
    "        'apr_micro': apr_micro,\n",
    "        'apr_weighted': apr_weighted\n",
    "    })\n",
    "    \n",
    "rdf = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "auc_ovr         0.998309\n",
       "auc_ovo         0.998308\n",
       "apr_macro       0.996224\n",
       "apr_micro       0.996087\n",
       "apr_weighted    0.996239\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines, column transformers, grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hand</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pizza apple orange</td>\n",
       "      <td>left</td>\n",
       "      <td>m</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>potato tomato greens pizza</td>\n",
       "      <td>right</td>\n",
       "      <td>f</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer monitor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mouse keyboard</td>\n",
       "      <td>left</td>\n",
       "      <td>m</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         text   hand gender   age  y\n",
       "0          pizza apple orange   left      m  22.2  1\n",
       "1  potato tomato greens pizza  right      f  32.3  1\n",
       "2            computer monitor    NaN      f  44.4  0\n",
       "3              mouse keyboard   left      m  55.5  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': ['pizza apple orange', 'potato tomato greens pizza', 'computer monitor', 'mouse keyboard'],\n",
    "    'hand': ['left', 'right', np.nan, 'left'],\n",
    "    'gender': ['m', 'f', 'f', 'm'],\n",
    "    'age': [22.2, 32.3, 44.4, 55.5],\n",
    "    'y': [1, 1, 0, 0]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "p0 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='')), \n",
    "    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape':-1})),\n",
    "    ('vectorize', CountVectorizer())\n",
    "])\n",
    "p1 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')), \n",
    "    ('ohe', OneHotEncoder(drop=['left']))\n",
    "])\n",
    "p2 = Pipeline(steps=[('ohe', OneHotEncoder(drop=['f']))])\n",
    "p4 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "t = ColumnTransformer([\n",
    "    ('text', p0, [0]),\n",
    "    ('hand', p1, [1]), \n",
    "    ('gender', p2, [2]),\n",
    "    ('age', p4, [3])\n",
    "], remainder='drop')\n",
    "\n",
    "\n",
    "T = t.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'computer',\n",
       " 'greens',\n",
       " 'keyboard',\n",
       " 'monitor',\n",
       " 'mouse',\n",
       " 'orange',\n",
       " 'pizza',\n",
       " 'potato',\n",
       " 'tomato',\n",
       " 'x0_right',\n",
       " 'x0_m',\n",
       " 'age']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_fields = t.named_transformers_['text'].named_steps['vectorize'].get_feature_names()\n",
    "h_fields = list(t.named_transformers_['hand'].named_steps['ohe'].get_feature_names())\n",
    "g_fields = list(t.named_transformers_['gender'].named_steps['ohe'].get_feature_names())\n",
    "o_fields = ['age']\n",
    "\n",
    "fields = t_fields + h_fields + g_fields + o_fields\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apple</th>\n",
       "      <th>computer</th>\n",
       "      <th>greens</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>monitor</th>\n",
       "      <th>mouse</th>\n",
       "      <th>orange</th>\n",
       "      <th>pizza</th>\n",
       "      <th>potato</th>\n",
       "      <th>tomato</th>\n",
       "      <th>x0_right</th>\n",
       "      <th>x0_m</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.308967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.502835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.348874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apple  computer  greens  keyboard  monitor  mouse  orange  pizza  potato  \\\n",
       "0    1.0       0.0     0.0       0.0      0.0    0.0     1.0    1.0     0.0   \n",
       "1    0.0       0.0     1.0       0.0      0.0    0.0     0.0    1.0     1.0   \n",
       "2    0.0       1.0     0.0       0.0      1.0    0.0     0.0    0.0     0.0   \n",
       "3    0.0       0.0     0.0       1.0      0.0    1.0     0.0    0.0     0.0   \n",
       "\n",
       "   tomato  x0_right  x0_m       age  \n",
       "0     0.0       0.0   1.0 -1.308967  \n",
       "1     1.0       1.0   0.0 -0.502835  \n",
       "2     0.0       0.0   0.0  0.462927  \n",
       "3     0.0       0.0   1.0  1.348874  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(T, columns=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p0 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='')), \n",
    "    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape':-1})),\n",
    "    ('vectorize', CountVectorizer())\n",
    "])\n",
    "p1 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')), \n",
    "    ('ohe', OneHotEncoder(drop=['left']))\n",
    "])\n",
    "p2 = Pipeline(steps=[('ohe', OneHotEncoder(drop=['f']))])\n",
    "p4 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "t = ColumnTransformer([\n",
    "    ('text', p0, [0]),\n",
    "    ('hand', p1, [1]), \n",
    "    ('gender', p2, [2]),\n",
    "    ('age', p4, [3])\n",
    "], remainder='drop')\n",
    "\n",
    "m = Pipeline(steps=[\n",
    "    ('preprocess', t),\n",
    "    ('regressor', LogisticRegression())\n",
    "])\n",
    "\n",
    "X, y = df[[c for c in df.columns if c != 'y']], df['y']\n",
    "\n",
    "m.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80466472, 0.78462158, 0.24182963, 0.16886457])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept   -0.333244\n",
       "apple        0.195329\n",
       "computer    -0.241834\n",
       "greens       0.215375\n",
       "keyboard    -0.168860\n",
       "monitor     -0.241834\n",
       "mouse       -0.168860\n",
       "orange       0.195329\n",
       "pizza        0.410704\n",
       "potato       0.215375\n",
       "tomato       0.215375\n",
       "x0_right     0.215375\n",
       "x0_m         0.026470\n",
       "age         -0.703700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    pd.Series(m.named_steps['regressor'].intercept_, ['intercept']),\n",
    "    pd.Series(m.named_steps['regressor'].coef_[0], fields)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 5), (40, 4), (40,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "df = pd.DataFrame({\n",
    "    'text': ['pizza apple orange', 'potato tomato greens pizza', 'computer monitor', 'mouse keyboard'] * N,\n",
    "    'hand': ['left', 'right', np.nan, 'left'] * N,\n",
    "    'gender': ['m', 'f', 'f', 'm'] * N,\n",
    "    'age': [22.2, 32.3, 44.4, 55.5] * N,\n",
    "    'y': [1, 1, 0, 0] * N\n",
    "})\n",
    "\n",
    "X, y = df[[c for c in df.columns if c != 'y']], df['y']\n",
    "\n",
    "df.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__random_state': 29}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='')), \n",
    "    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape':-1})),\n",
    "    ('vectorize', CountVectorizer())\n",
    "])\n",
    "p1 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')), \n",
    "    ('ohe', OneHotEncoder(drop=['left']))\n",
    "])\n",
    "p2 = Pipeline(steps=[('ohe', OneHotEncoder(drop=['f']))])\n",
    "p4 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "t = ColumnTransformer([\n",
    "    ('text', p0, [0]),\n",
    "    ('hand', p1, [1]), \n",
    "    ('gender', p2, [2]),\n",
    "    ('age', p4, [3])\n",
    "], remainder='drop')\n",
    "\n",
    "e = Pipeline(steps=[\n",
    "    ('preprocess', t),\n",
    "    ('regressor', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(**{\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "m = GridSearchCV(**{\n",
    "    'estimator': e,\n",
    "    'cv': cv,\n",
    "    'param_grid': {\n",
    "        'regressor__random_state': [29, 37]\n",
    "    },\n",
    "    'scoring': {\n",
    "        'auc': 'roc_auc',\n",
    "        'apr': 'average_precision'\n",
    "    },\n",
    "    'verbose': 5,\n",
    "    'refit': 'auc',\n",
    "    'error_score': np.NaN,\n",
    "    'n_jobs': -1\n",
    "})\n",
    "\n",
    "m.fit(X, y)\n",
    "m.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95717104, 0.94940778, 0.06120815, 0.03221605, 0.95717104,\n",
       "       0.94940778, 0.06120815, 0.03221605, 0.95717104, 0.94940778,\n",
       "       0.06120815, 0.03221605, 0.95717104, 0.94940778, 0.06120815,\n",
       "       0.03221605, 0.95717104, 0.94940778, 0.06120815, 0.03221605,\n",
       "       0.95717104, 0.94940778, 0.06120815, 0.03221605, 0.95717104,\n",
       "       0.94940778, 0.06120815, 0.03221605, 0.95717104, 0.94940778,\n",
       "       0.06120815, 0.03221605, 0.95717104, 0.94940778, 0.06120815,\n",
       "       0.03221605, 0.95717104, 0.94940778, 0.06120815, 0.03221605])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept   -0.796608\n",
       "apple        0.428280\n",
       "computer    -0.612042\n",
       "greens       0.505914\n",
       "keyboard    -0.322175\n",
       "monitor     -0.612042\n",
       "mouse       -0.322175\n",
       "orange       0.428280\n",
       "pizza        0.934194\n",
       "potato       0.505914\n",
       "tomato       0.505914\n",
       "x0_right     0.505914\n",
       "x0_m         0.106105\n",
       "age         -1.532901\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    pd.Series(m.best_estimator_.named_steps['regressor'].intercept_, ['intercept']),\n",
    "    pd.Series(m.best_estimator_.named_steps['regressor'].coef_[0], fields)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  50 | elapsed:    0.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  50 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  50 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  50 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__C': 0.8861628575625455,\n",
       " 'regressor__l1_ratio': 0.44678402377577453,\n",
       " 'regressor__random_state': 11}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "p0 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='')), \n",
    "    ('reshape', FunctionTransformer(np.reshape, kw_args={'newshape':-1})),\n",
    "    ('vectorize', CountVectorizer())\n",
    "])\n",
    "p1 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')), \n",
    "    ('ohe', OneHotEncoder(drop=['left']))\n",
    "])\n",
    "p2 = Pipeline(steps=[('ohe', OneHotEncoder(drop=['f']))])\n",
    "p4 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "t = ColumnTransformer([\n",
    "    ('text', p0, [0]),\n",
    "    ('hand', p1, [1]), \n",
    "    ('gender', p2, [2]),\n",
    "    ('age', p4, [3])\n",
    "], remainder='drop')\n",
    "\n",
    "e = Pipeline(steps=[\n",
    "    ('preprocess', t),\n",
    "    ('regressor', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(**{\n",
    "    'n_splits': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 37\n",
    "})\n",
    "\n",
    "uniform.random_state = 37\n",
    "randint.random_state = 37\n",
    "\n",
    "regressor__C_dist = uniform()\n",
    "regressor__l1_ratio_dist = uniform() \n",
    "regressor__random_state_dist = randint(5, 40)\n",
    "\n",
    "regressor__C_dist.random_state = 37\n",
    "regressor__l1_ratio_dist.random_state = 37\n",
    "regressor__random_state_dist.random_state = 37\n",
    "\n",
    "m = RandomizedSearchCV(**{\n",
    "    'estimator': e,\n",
    "    'cv': cv,\n",
    "    'param_distributions': {\n",
    "        'regressor__random_state': regressor__random_state_dist,\n",
    "        'regressor__C': regressor__C_dist,\n",
    "        'regressor__l1_ratio': regressor__l1_ratio_dist\n",
    "    },\n",
    "    'scoring': {\n",
    "        'auc': 'roc_auc',\n",
    "        'apr': 'average_precision'\n",
    "    },\n",
    "    'verbose': 5,\n",
    "    'refit': 'auc',\n",
    "    'error_score': np.NaN,\n",
    "    'n_jobs': -1\n",
    "})\n",
    "\n",
    "m.fit(X, y)\n",
    "m.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01352501, 0.01620173, 0.01874933, 0.02089486, 0.02180014,\n",
       "        0.02144923, 0.02035055, 0.02146559, 0.02045355, 0.01744499]),\n",
       " 'std_fit_time': array([0.0004663 , 0.00136882, 0.00298622, 0.00060401, 0.00092841,\n",
       "        0.00107438, 0.00205119, 0.00129154, 0.00327625, 0.00285363]),\n",
       " 'mean_score_time': array([0.01998224, 0.01063399, 0.01161842, 0.0110549 , 0.01962199,\n",
       "        0.01082191, 0.00972252, 0.0092669 , 0.00763993, 0.00690565]),\n",
       " 'std_score_time': array([0.02239441, 0.00060964, 0.00199941, 0.0005795 , 0.01610719,\n",
       "        0.00037426, 0.00064848, 0.00127296, 0.00166517, 0.00075786]),\n",
       " 'param_regressor__C': masked_array(data=[0.8861628575625455, 0.2669851105048685,\n",
       "                    0.18394258557069376, 0.07618735142456279,\n",
       "                    0.5057860075182486, 0.20365586920932577,\n",
       "                    0.5846689895186896, 0.7451596080317253,\n",
       "                    0.4187299961837905, 0.7330989808813632],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_regressor__l1_ratio': masked_array(data=[0.44678402377577453, 0.7932726296280042,\n",
       "                    0.02419288751414972, 0.33254214738505705,\n",
       "                    0.17149139198746954, 0.32804028992640133,\n",
       "                    0.338890624803148, 0.04340148929509069,\n",
       "                    0.46658684845827336, 0.6470581061933899],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_regressor__random_state': masked_array(data=[11, 23, 25, 13, 20, 34, 26, 18, 38, 22],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'regressor__C': 0.8861628575625455,\n",
       "   'regressor__l1_ratio': 0.44678402377577453,\n",
       "   'regressor__random_state': 11},\n",
       "  {'regressor__C': 0.2669851105048685,\n",
       "   'regressor__l1_ratio': 0.7932726296280042,\n",
       "   'regressor__random_state': 23},\n",
       "  {'regressor__C': 0.18394258557069376,\n",
       "   'regressor__l1_ratio': 0.02419288751414972,\n",
       "   'regressor__random_state': 25},\n",
       "  {'regressor__C': 0.07618735142456279,\n",
       "   'regressor__l1_ratio': 0.33254214738505705,\n",
       "   'regressor__random_state': 13},\n",
       "  {'regressor__C': 0.5057860075182486,\n",
       "   'regressor__l1_ratio': 0.17149139198746954,\n",
       "   'regressor__random_state': 20},\n",
       "  {'regressor__C': 0.20365586920932577,\n",
       "   'regressor__l1_ratio': 0.32804028992640133,\n",
       "   'regressor__random_state': 34},\n",
       "  {'regressor__C': 0.5846689895186896,\n",
       "   'regressor__l1_ratio': 0.338890624803148,\n",
       "   'regressor__random_state': 26},\n",
       "  {'regressor__C': 0.7451596080317253,\n",
       "   'regressor__l1_ratio': 0.04340148929509069,\n",
       "   'regressor__random_state': 18},\n",
       "  {'regressor__C': 0.4187299961837905,\n",
       "   'regressor__l1_ratio': 0.46658684845827336,\n",
       "   'regressor__random_state': 38},\n",
       "  {'regressor__C': 0.7330989808813632,\n",
       "   'regressor__l1_ratio': 0.6470581061933899,\n",
       "   'regressor__random_state': 22}],\n",
       " 'split0_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split3_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split4_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_auc': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'std_test_auc': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'rank_test_auc': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'split0_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split1_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split3_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split4_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'mean_test_apr': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'std_test_apr': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'rank_test_apr': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
