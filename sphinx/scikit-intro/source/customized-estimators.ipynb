{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mineral-salad",
   "metadata": {},
   "source": [
    "# Customized Estimators\n",
    "\n",
    "You are able to [roll your own](https://scikit-learn.org/stable/developers/develop.html) `estimator`, `regressor`, `classifier` or `transformer`. Below are some templates adapted from [the GitHub repository](https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/_template.py) and works with scikit-learn v0.24.1 (the GitHub repository for the [project-template](https://github.com/scikit-learn-contrib/project-template) is independent from and not synchronized with the [scikit-learn](https://github.com/scikit-learn/scikit-learn/tree/0.24.1) repository). There is also [official documentation](https://sklearn-template.readthedocs.io/en/latest/index.html) elsewhere.\n",
    "\n",
    "Note that you should (though not necessarily) inherit from `BaseEstimator` and use the appropriate `mixin`. After you write your estimator, apply the `check_estimator()` method to check (test) if your estimator is valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-locator",
   "metadata": {},
   "source": [
    "## Basic estimator\n",
    "\n",
    "Here is a barebones, dummy estimator. You need to implement two methods with the following signatures.\n",
    "\n",
    "- fit(self, X, y, **kwargs)\n",
    "- predict(self, X)\n",
    "\n",
    "When you run `fit()`, make sure the first thing you do is check if `y` is `None`. The `check_X_y()` method is also required, and the properties `is_fitted_` and `n_features_in_` are also required to be set inside `fit()`. At the end of `fit()`, `self` must always be returned.\n",
    "\n",
    "The `predict()` method must return a prediction for every row. Likewise, before making any predictions, `check_is_fitted()` and `check_array()` are required to be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "approved-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "class SpecialEstimator(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        if y is None:\n",
    "            raise ValueError('requires y to be passed, but the target y is None')\n",
    "            \n",
    "        X, y = check_X_y(X, y)\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        X = check_array(X)\n",
    "        return np.ones(X.shape[0], dtype=np.int64)\n",
    "\n",
    "check_estimator(SpecialEstimator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-whole",
   "metadata": {},
   "source": [
    "## Basic regressor\n",
    "\n",
    "If your estimator is indeed a regressor, use `RegressorMixin`. The `fit()` and `predict()` implementations follows the same as before. However, notice the `_more_tags()` method? This method is used to override or supply additional `tags`. As of v0.24.1, the documentation states that tags are experimental and subject to change. But [what are these tags](https://scikit-learn.org/stable/developers/develop.html#estimator-tags)? These tags are essentially hints about the capabilities of the estimator. The `poor_score` tag hints that the regressor either fails (`True`) or not fails (`False`, default) to provide a *reasonable* test-set score. By default, this tag is set to `False`, and here, we implement `_more_tags()` to override that value to `True` (otherwise, there is a warning generated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noble-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        if y is None:\n",
    "            raise ValueError('requires y to be passed, but the target y is None')\n",
    "            \n",
    "        X, y = check_X_y(X, y)\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        X = check_array(X)\n",
    "        return np.ones(X.shape[0], dtype=np.int64)\n",
    "    \n",
    "    def _more_tags(self):\n",
    "        return {\n",
    "            'poor_score': True\n",
    "        }\n",
    "    \n",
    "check_estimator(SpecialRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-darwin",
   "metadata": {},
   "source": [
    "## Basic classifier\n",
    "\n",
    "Classifiers should use `ClassifierMixin`, and also follow the `fit()` and `predict()` contracts. One caveate here is that in the `fit()` method, we must also store the state of the number of classes in `classes_`. Be careful with the `predict()` method, as it should return label values that are consistent with the class values seen during `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minus-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class SpecialClassifier(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        if y is None:\n",
    "            raise ValueError('requires y to be passed, but the target y is None')\n",
    "        \n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.is_fitted_ = True\n",
    "                \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['is_fitted_', 'X_', 'y_'])\n",
    "        X = check_array(X)\n",
    "        \n",
    "        closest = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
    "        return self.y_[closest]\n",
    "    \n",
    "check_estimator(SpecialClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-hampshire",
   "metadata": {},
   "source": [
    "## Basic transformer\n",
    "\n",
    "Transformers should use `TransformerMixin` and implement two methods.\n",
    "\n",
    "- fit(self, X, y=None)\n",
    "- transform(self, X)\n",
    "\n",
    "The check and properties saved shown below inside `fit()` and `transform()` are all required to pass the checks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "environmental-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        \n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.is_fitted_ = True\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, ['is_fitted_'])\n",
    "        \n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        \n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError('Shape of input is different from what was seen in `fit`')\n",
    "            \n",
    "        return np.sqrt(X)\n",
    "    \n",
    "check_estimator(SpecialTransformer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-period",
   "metadata": {},
   "source": [
    "## Custom estimator with pipeline\n",
    "\n",
    "Below, we illustrate the use of create a custom estimator using a pipeline. The pipeline is very simple, we first rescale the data followed by a regression. We will use the `California housing data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "whole-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prerequisite-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "democratic-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.526\n",
       "1    3.585\n",
       "2    3.521\n",
       "3    3.413\n",
       "4    3.422\n",
       "Name: MedHouseVal, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-senegal",
   "metadata": {},
   "source": [
    "Now, we will define our `AwesomeEstimator`. Notice how we pass in the hyperparameters to tune as a part of the `fit()` function and [not the constructor](https://scikit-learn.org/stable/developers/develop.html#parameters-and-init)? It is very expensive and tricky to validate these models with `check_estimator()` since there is searching involve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "falling-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "class AwesomeEstimator(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __get_pipeline(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        regressor = RandomForestRegressor(**{\n",
    "            'random_state': 37\n",
    "        })\n",
    "        \n",
    "        steps=[\n",
    "            ('scaler', scaler), \n",
    "            ('regressor', regressor)]\n",
    "        \n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        return pipeline\n",
    "    \n",
    "    def __get_model(self, feature_range, n_estimators):\n",
    "        model = GridSearchCV(**{\n",
    "            'estimator': self.__get_pipeline(),\n",
    "            'cv': 5,\n",
    "            'param_grid': {\n",
    "                'scaler__feature_range': feature_range,\n",
    "                'regressor__n_estimators': n_estimators\n",
    "            },\n",
    "            'scoring': 'neg_mean_absolute_error',\n",
    "            'verbose': 5,\n",
    "            'refit': 'neg_mean_absolute_error',\n",
    "            'error_score': np.NaN,\n",
    "            'n_jobs': -1\n",
    "        })\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, feature_range=[(0, 1)], n_estimators=[100]):\n",
    "        if y is None:\n",
    "            raise ValueError('requires y to be passed, but the target y is None')\n",
    "            \n",
    "        X, y = check_X_y(X, y)\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        self.model_ = self.__get_model(feature_range, n_estimators)\n",
    "        self.model_.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['is_fitted_', 'model_'])\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "check_estimator(AwesomeEstimator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-representation",
   "metadata": {},
   "source": [
    "Let's run the `AwesomeEstimator` using the default grid search values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "measured-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "mae 0.11960, rmse 0.18588, rsq 0.97405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "estimator = AwesomeEstimator()\n",
    "estimator.fit(X, y)\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "rsq = r2_score(y, y_pred)\n",
    "\n",
    "print(f'mae {mae:.5f}, rmse {mse:.5f}, rsq {rsq:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-intermediate",
   "metadata": {},
   "source": [
    "We can also expand the search with additional hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "identified-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "mae 0.11846, rmse 0.18360, rsq 0.97468\n"
     ]
    }
   ],
   "source": [
    "estimator = AwesomeEstimator()\n",
    "estimator.fit(X, y, feature_range=[(0, 1), (0, 5)], n_estimators=[100, 200])\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "rsq = r2_score(y, y_pred)\n",
    "\n",
    "print(f'mae {mae:.5f}, rmse {mse:.5f}, rsq {rsq:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "valid-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__n_estimators': 200, 'scaler__feature_range': (0, 1)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
