{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import *\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "\n",
    "class ShapeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=transforms.Compose([Resize(256), RandomCrop(224), ToTensor()])):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.__init()\n",
    "    \n",
    "    def __init(self):\n",
    "        self.jpg_files = [f for f in pathlib.Path(self.root_dir).glob('**/*.jpg') \n",
    "                          if '.ipynb_checkpoints' not in f.parts]\n",
    "        self.class_to_idx = {clazz: i for i, clazz in enumerate(['circle', 'poly', 'rect'])}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.jpg_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.jpg_files[idx]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        clazz = self.class_to_idx[img_path.parts[2]]\n",
    "        \n",
    "        return image, clazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShapeDataset('./shapes/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('shapes/train/rect/0026.jpg'),\n",
       " PosixPath('shapes/train/rect/0029.jpg'),\n",
       " PosixPath('shapes/train/rect/0024.jpg'),\n",
       " PosixPath('shapes/train/rect/0023.jpg'),\n",
       " PosixPath('shapes/train/rect/0021.jpg'),\n",
       " PosixPath('shapes/train/rect/0028.jpg'),\n",
       " PosixPath('shapes/train/rect/0025.jpg'),\n",
       " PosixPath('shapes/train/rect/0022.jpg'),\n",
       " PosixPath('shapes/train/rect/0027.jpg'),\n",
       " PosixPath('shapes/train/rect/0020.jpg'),\n",
       " PosixPath('shapes/train/poly/0012.jpg'),\n",
       " PosixPath('shapes/train/poly/0016.jpg'),\n",
       " PosixPath('shapes/train/poly/0011.jpg'),\n",
       " PosixPath('shapes/train/poly/0018.jpg'),\n",
       " PosixPath('shapes/train/poly/0015.jpg'),\n",
       " PosixPath('shapes/train/poly/0017.jpg'),\n",
       " PosixPath('shapes/train/poly/0010.jpg'),\n",
       " PosixPath('shapes/train/poly/0014.jpg'),\n",
       " PosixPath('shapes/train/poly/0013.jpg'),\n",
       " PosixPath('shapes/train/poly/0019.jpg'),\n",
       " PosixPath('shapes/train/circle/0008.jpg'),\n",
       " PosixPath('shapes/train/circle/0007.jpg'),\n",
       " PosixPath('shapes/train/circle/0006.jpg'),\n",
       " PosixPath('shapes/train/circle/0005.jpg'),\n",
       " PosixPath('shapes/train/circle/0009.jpg'),\n",
       " PosixPath('shapes/train/circle/0001.jpg'),\n",
       " PosixPath('shapes/train/circle/0000.jpg'),\n",
       " PosixPath('shapes/train/circle/0002.jpg'),\n",
       " PosixPath('shapes/train/circle/0004.jpg'),\n",
       " PosixPath('shapes/train/circle/0003.jpg')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.jpg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "1 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "2 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "3 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "4 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "5 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "6 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "7 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "8 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "9 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "10 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "11 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "12 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "13 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "14 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "15 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "16 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "17 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "18 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "19 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "20 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "21 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "22 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "23 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "24 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "25 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "26 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "27 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "28 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "29 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    print(i, type(dataset[i]), \n",
    "          type(dataset[i][0]),\n",
    "          type(dataset[i][1]),\n",
    "          dataset[i][1], \n",
    "          dataset[i][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "transform = transforms.Compose([Resize(256), RandomCrop(224), ToTensor()])\n",
    "image_folder = datasets.ImageFolder('./shapes/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circle', 'poly', 'rect']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circle 0\n",
      "poly 1\n",
      "rect 2\n"
     ]
    }
   ],
   "source": [
    "for clazz in image_folder.classes:\n",
    "    print(clazz, image_folder.class_to_idx[clazz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "1 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "2 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "3 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "4 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "5 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "6 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "7 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "8 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "9 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 torch.Size([3, 224, 224])\n",
      "10 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "11 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "12 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "13 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "14 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "15 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "16 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "17 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "18 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "19 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 1 torch.Size([3, 224, 224])\n",
      "20 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "21 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "22 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "23 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "24 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "25 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "26 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "27 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "28 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n",
      "29 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 2 torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_folder)):\n",
    "    print(i, type(image_folder[i]), \n",
    "          type(image_folder[i][0]),\n",
    "          type(image_folder[i][1]),\n",
    "          image_folder[i][1], \n",
    "          image_folder[i][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "1 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "2 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "3 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "4 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "5 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "6 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "7 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "8 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "9 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "10 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "11 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "12 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "13 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "14 <class 'list'> 2 <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, \n",
    "          type(sample_batched), len(sample_batched),\n",
    "          type(sample_batched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    print(type(inputs), type(labels), ':', inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(image_folder, batch_size=2, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "1 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "2 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "3 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "4 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "5 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "6 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "7 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "8 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "9 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "10 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "11 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "12 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "13 <class 'list'> 2 <class 'torch.Tensor'>\n",
      "14 <class 'list'> 2 <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, \n",
    "          type(sample_batched), len(sample_batched),\n",
    "          type(sample_batched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> : torch.Size([2, 3, 224, 224]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    print(type(inputs), type(labels), ':', inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([0, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n",
      "tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading tensors to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n",
      "tensor([0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "tensor([0, 0], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'device = {device}')\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Here are a few datasets accessible through the PyTorch API that you may load.\n",
    "\n",
    "### MNIST\n",
    "\n",
    "A handwritten digit [database](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "data_root = './output/mnist'\n",
    "num_workers = 4\n",
    "batch_size = 64\n",
    "\n",
    "dataset = datasets.MNIST(root=data_root, download=True, transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST\n",
    "\n",
    "An `article` (clothing) [database](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './output/fasionmnist'\n",
    "dataset = datasets.FashionMNIST(root=data_root, download=True, transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMNIST\n",
    "\n",
    "Kuzushiji [database](https://github.com/rois-codh/kmnist) of classic Japanese characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './output/kmnist'\n",
    "dataset = datasets.KMNIST(root=data_root, download=True, transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMNIST\n",
    "\n",
    "A handwritten character digit [database](https://www.nist.gov/node/1298471/emnist-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './output/emnist'\n",
    "dataset = datasets.EMNIST(root=data_root, split='byclass', download=True, transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QMNIST\n",
    "\n",
    "A handwritten character digit [database](https://github.com/facebookresearch/qmnist) based on `EMNIST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './output/qmnist'\n",
    "dataset = datasets.QMNIST(root=data_root, download=True, transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FakeData\n",
    "\n",
    "A fake dataset that returns randomly generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.FakeData(size=1000, \n",
    "                            image_size=(3, 224, 224), \n",
    "                            num_classes=10, transform=None, \n",
    "                            target_transform=None, random_offset=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSUN\n",
    "\n",
    "A [dataset](https://github.com/fyu/lsun) of 10 scene categories and 20 object categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './output/lsun'\n",
    "dataset = datasets.LSUN(root=data_root, classes='train', transform=None)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
