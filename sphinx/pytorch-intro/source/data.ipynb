{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import *\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "\n",
    "class ShapeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=transforms.Compose([Resize(256), RandomCrop(224), ToTensor()])):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.__init()\n",
    "    \n",
    "    def __init(self):\n",
    "        self.jpg_files = [f for f in pathlib.Path(self.root_dir).glob('**/*.jpg') \n",
    "                          if '.ipynb_checkpoints' not in f.parts]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.jpg_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.jpg_files[idx]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        sample = {'image': image, 'class': img_path.parts[2]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShapeDataset('./shapes/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('shapes/train/rect/0026.jpg'),\n",
       " PosixPath('shapes/train/rect/0029.jpg'),\n",
       " PosixPath('shapes/train/rect/0024.jpg'),\n",
       " PosixPath('shapes/train/rect/0023.jpg'),\n",
       " PosixPath('shapes/train/rect/0021.jpg'),\n",
       " PosixPath('shapes/train/rect/0028.jpg'),\n",
       " PosixPath('shapes/train/rect/0025.jpg'),\n",
       " PosixPath('shapes/train/rect/0022.jpg'),\n",
       " PosixPath('shapes/train/rect/0027.jpg'),\n",
       " PosixPath('shapes/train/rect/0020.jpg'),\n",
       " PosixPath('shapes/train/poly/0012.jpg'),\n",
       " PosixPath('shapes/train/poly/0016.jpg'),\n",
       " PosixPath('shapes/train/poly/0011.jpg'),\n",
       " PosixPath('shapes/train/poly/0018.jpg'),\n",
       " PosixPath('shapes/train/poly/0015.jpg'),\n",
       " PosixPath('shapes/train/poly/0017.jpg'),\n",
       " PosixPath('shapes/train/poly/0010.jpg'),\n",
       " PosixPath('shapes/train/poly/0014.jpg'),\n",
       " PosixPath('shapes/train/poly/0013.jpg'),\n",
       " PosixPath('shapes/train/poly/0019.jpg'),\n",
       " PosixPath('shapes/train/circle/0008.jpg'),\n",
       " PosixPath('shapes/train/circle/0007.jpg'),\n",
       " PosixPath('shapes/train/circle/0006.jpg'),\n",
       " PosixPath('shapes/train/circle/0005.jpg'),\n",
       " PosixPath('shapes/train/circle/0009.jpg'),\n",
       " PosixPath('shapes/train/circle/0001.jpg'),\n",
       " PosixPath('shapes/train/circle/0000.jpg'),\n",
       " PosixPath('shapes/train/circle/0002.jpg'),\n",
       " PosixPath('shapes/train/circle/0004.jpg'),\n",
       " PosixPath('shapes/train/circle/0003.jpg')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.jpg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([3, 224, 224]) rect\n",
      "1 torch.Size([3, 224, 224]) rect\n",
      "2 torch.Size([3, 224, 224]) rect\n",
      "3 torch.Size([3, 224, 224]) rect\n",
      "4 torch.Size([3, 224, 224]) rect\n",
      "5 torch.Size([3, 224, 224]) rect\n",
      "6 torch.Size([3, 224, 224]) rect\n",
      "7 torch.Size([3, 224, 224]) rect\n",
      "8 torch.Size([3, 224, 224]) rect\n",
      "9 torch.Size([3, 224, 224]) rect\n",
      "10 torch.Size([3, 224, 224]) poly\n",
      "11 torch.Size([3, 224, 224]) poly\n",
      "12 torch.Size([3, 224, 224]) poly\n",
      "13 torch.Size([3, 224, 224]) poly\n",
      "14 torch.Size([3, 224, 224]) poly\n",
      "15 torch.Size([3, 224, 224]) poly\n",
      "16 torch.Size([3, 224, 224]) poly\n",
      "17 torch.Size([3, 224, 224]) poly\n",
      "18 torch.Size([3, 224, 224]) poly\n",
      "19 torch.Size([3, 224, 224]) poly\n",
      "20 torch.Size([3, 224, 224]) circle\n",
      "21 torch.Size([3, 224, 224]) circle\n",
      "22 torch.Size([3, 224, 224]) circle\n",
      "23 torch.Size([3, 224, 224]) circle\n",
      "24 torch.Size([3, 224, 224]) circle\n",
      "25 torch.Size([3, 224, 224]) circle\n",
      "26 torch.Size([3, 224, 224]) circle\n",
      "27 torch.Size([3, 224, 224]) circle\n",
      "28 torch.Size([3, 224, 224]) circle\n",
      "29 torch.Size([3, 224, 224]) circle\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    print(i, sample['image'].shape, sample['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "transform = transforms.Compose([Resize(256), RandomCrop(224), ToTensor()])\n",
    "image_folder = datasets.ImageFolder('./shapes/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['circle', 'poly', 'rect']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circle 0\n",
      "poly 1\n",
      "rect 2\n"
     ]
    }
   ],
   "source": [
    "for clazz in image_folder.classes:\n",
    "    print(clazz, image_folder.class_to_idx[clazz])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 3, 224, 224])\n",
      "1 torch.Size([2, 3, 224, 224])\n",
      "2 torch.Size([2, 3, 224, 224])\n",
      "3 torch.Size([2, 3, 224, 224])\n",
      "4 torch.Size([2, 3, 224, 224])\n",
      "5 torch.Size([2, 3, 224, 224])\n",
      "6 torch.Size([2, 3, 224, 224])\n",
      "7 torch.Size([2, 3, 224, 224])\n",
      "8 torch.Size([2, 3, 224, 224])\n",
      "9 torch.Size([2, 3, 224, 224])\n",
      "10 torch.Size([2, 3, 224, 224])\n",
      "11 torch.Size([2, 3, 224, 224])\n",
      "12 torch.Size([2, 3, 224, 224])\n",
      "13 torch.Size([2, 3, 224, 224])\n",
      "14 torch.Size([2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched['image'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(image_folder, batch_size=2, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-036e7d71db5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_index_sampler',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'pin_memory',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
