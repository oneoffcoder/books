{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1])\n",
      "b: tensor([1, 2])\n",
      "c: tensor([1., 2.])\n",
      "d: tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "e: tensor([1., 2., 3.])\n",
      "f: tensor([1., 2.], dtype=torch.float64)\n",
      "g: tensor([0.])\n",
      "h: tensor([[0., 0.]])\n",
      "i: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "j: tensor([[4.2039e-45, 4.4645e-42],\n",
      "        [9.5925e-40, 1.1652e-32]])\n",
      "k: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "l: tensor([0, 1, 2, 3, 4])\n",
      "m: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "n: tensor([ 1.0000,  1.7783,  3.1623,  5.6234, 10.0000])\n",
      "o: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "p: tensor([[7., 7., 7.],\n",
      "        [7., 7., 7.],\n",
      "        [7., 7., 7.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# one element\n",
    "a = torch.tensor([1])\n",
    "\n",
    "# two element\n",
    "b = torch.tensor([1, 2])\n",
    "\n",
    "# two float elements\n",
    "c = torch.tensor([1., 2.])\n",
    "\n",
    "# matrix \n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "\n",
    "# from python array\n",
    "e = torch.as_tensor([1., 2., 3.], dtype=torch.float32)\n",
    "\n",
    "# from numpy array\n",
    "f = torch.from_numpy(np.array([1.0, 2.0]))\n",
    "\n",
    "# make tensor of zeros\n",
    "g = torch.zeros(1)\n",
    "h = torch.zeros(1, 2)\n",
    "i = torch.zeros(2, 2)\n",
    "\n",
    "# empty tensor\n",
    "j = torch.empty(2, 2)\n",
    "\n",
    "# make tensor ones\n",
    "k = torch.ones(2, 2)\n",
    "\n",
    "# make tensor from range\n",
    "l = torch.arange(start=0, end=5, step=1)\n",
    "\n",
    "# make tensor from line space\n",
    "m = torch.linspace(start=0, end=1, steps=5)\n",
    "\n",
    "# make tensor from log space\n",
    "n = torch.logspace(start=0, end=1, steps=5)\n",
    "\n",
    "# make identity matrix\n",
    "o = torch.eye(n=3, m=3)\n",
    "\n",
    "# matrix whose elements are all same values\n",
    "p = torch.full(size=(3, 3), fill_value=7)\n",
    "\n",
    "results = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p]\n",
    "for c, r in zip(list('abcdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bridge\n",
    "\n",
    "Tensors may be converted to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 2.])\n",
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays may also be converted back to Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2], dtype=np.float)\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, slicing, joining and mutating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 2., 3.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 2.])\n",
    "b = torch.tensor([2., 3.])\n",
    "torch.cat((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2.], [3., 4.]])\n",
    "b = torch.flatten(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2.], [3., 4.]])\n",
    "b = torch.flip(a, dims=[0, 1])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "i = torch.tensor([1])\n",
    "torch.index_select(a, dim=1, index=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuting\n",
    "\n",
    "Some data come in `HWC` (height, width, channel) format, but PyTorch needs `CHW` format. Here's how to `permute` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 480, 3])\n",
      "torch.Size([3, 640, 480])\n"
     ]
    }
   ],
   "source": [
    "hwc = torch.rand(640, 480, 3)\n",
    "chw = hwc.permute(2, 0, 1)\n",
    "\n",
    "print(hwc.shape)\n",
    "print(chw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "\n",
    "Some data come as a single array, but you may reshape it into a tensor with different dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(784)\n",
    "b = a.view(1, 28, 28)\n",
    "c = a.reshape(1, 28, 28)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing\n",
    "\n",
    "Get rid of all the dimensions with `size 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 1, 2, 1, 2])\n",
      "b:  torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# a 2x1x2x1x2 tensor\n",
    "a = torch.zeros(2, 1, 2, 1, 2)\n",
    "b = torch.squeeze(a)\n",
    "\n",
    "print('a: ', a.shape)\n",
    "print('b: ', b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  torch.Size([2, 1, 2]) :  tensor([[[0., 0.]],\n",
      "\n",
      "        [[0., 0.]]])\n",
      "d:  torch.Size([1, 2, 2]) :  tensor([[[0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(1, 2)\n",
    "b = torch.zeros(1, 2)\n",
    "c = torch.stack([a, b], dim=0)\n",
    "d = torch.stack([a, b], dim=1)\n",
    "\n",
    "print('c: ', c.shape, ': ', c)\n",
    "print('d: ', d.shape, ': ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "b = torch.t(a)\n",
    "\n",
    "print('a: ', a.shape)\n",
    "print('b: ', b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.LongTensor\n",
    "a = torch.tensor([[0, 1], [2, 3]])\n",
    "\n",
    "# torch.FloatTensor\n",
    "b = a.to(dtype=torch.float32)\n",
    "b.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6910, 0.8778, 0.3101]),\n",
       " tensor([0.4176, 0.3738, 0.3886]),\n",
       " tensor([0.8491, 0.4955, 0.3924]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 3)\n",
    "b = torch.unbind(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([3])\n",
      "b:  torch.Size([1, 3])\n",
      "c:  torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.unsqueeze(a, 0)\n",
    "c = torch.unsqueeze(a, 1)\n",
    "\n",
    "print('a: ', a.shape)\n",
    "print('b: ', b.shape)\n",
    "print('c: ', c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0879, 1.0000, 0.2121],\n",
       "        [1.0000, 1.0000, 1.0000],\n",
       "        [0.6462, 1.0000, 0.6818]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "b = torch.ones(3, 3)\n",
    "torch.where(a > 0, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1.1063, 0.0471])\n",
      "b: tensor([[ 0.6093,  0.8607],\n",
      "        [-1.0625, -0.9297]])\n",
      "c: tensor([0.6415, 0.2973])\n",
      "d: tensor([[0.9616, 0.8872],\n",
      "        [0.5437, 0.6504]])\n",
      "e: tensor([[0, 7, 5, 1, 3]])\n",
      "f: tensor([2, 1, 3, 4, 0])\n",
      "g: tensor([1., 1., 1.])\n",
      "h: tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1])\n",
      "i: tensor([[-1.7465, -0.5181,  0.8286,  0.1691, -0.0902]])\n"
     ]
    }
   ],
   "source": [
    "# generates 2 random numbers, normal(0, 1)\n",
    "a = torch.randn(2)\n",
    "\n",
    "# generates 2x2 matrix of random numbers, normal(0, 1)\n",
    "b = torch.randn(2, 2)\n",
    "\n",
    "# generates 2 random numbers, uniform [0, 1]\n",
    "c = torch.rand(2)\n",
    "\n",
    "# generates 2x2 random numbers, uniform [0, 1]\n",
    "d = torch.rand(2, 2)\n",
    "\n",
    "# samples from [0, 10)\n",
    "e = torch.randint(low=0, high=10, size=(1, 5))\n",
    "\n",
    "# samples a random permutation fro [0, n)\n",
    "f = torch.randperm(5)\n",
    "\n",
    "# samples from a bernoulli distribution\n",
    "g = torch.bernoulli(torch.rand(3))\n",
    "\n",
    "# samples from a multinomial distribution\n",
    "weights = torch.tensor([5, 10], dtype=torch.float)\n",
    "h = torch.multinomial(input=weights, num_samples=10, replacement=True)\n",
    "\n",
    "# samples from a normal distribution\n",
    "i = torch.normal(0, 1, size=(1, 5))\n",
    "\n",
    "results = [a,b,c,d,e,f,g,h,i]\n",
    "for c, s in zip(list('abcdefghijklmopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1., 2.])\n",
      "b: tensor([2., 3., 4.])\n",
      "c: tensor([10, 11])\n",
      "d: tensor([ 0, 10])\n",
      "e: tensor([0.8509])\n",
      "f: tensor([0.5253])\n",
      "g: tensor([1.6198])\n",
      "h: tensor([0.4115])\n",
      "i: tensor([1.1593])\n",
      "j: tensor([0.3805])\n",
      "k: tensor([0.7854])\n",
      "l: tensor([ 0,  1, -5])\n",
      "m: tensor([-0., -1.,  2.,  1.])\n",
      "n: tensor([-1., -2.,  1.,  0.])\n",
      "o: tensor([-0.5000, -0.3000,  0.0000,  0.3000,  0.5000])\n",
      "p: tensor([7.3891])\n",
      "q: tensor([ 0, -1,  1,  0])\n",
      "r: tensor([0, 1, 1, 0])\n",
      "s: tensor([0.0000, 0.6931, 0.6931])\n",
      "t: tensor([False,  True])\n",
      "u: tensor([False, False,  True])\n",
      "v: tensor([1, 2])\n",
      "w: tensor([1., 4., 9.])\n",
      "x: tensor([1.0000, 0.5000, 0.3333])\n",
      "y: tensor([0.7613, 0.1120, 0.4234, 0.5516])\n",
      "z: tensor([-1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "# absolute value\n",
    "a = torch.abs(torch.tensor([-1., -2.]))\n",
    "\n",
    "# square root\n",
    "b = torch.sqrt(torch.tensor([4., 9., 16.]))\n",
    "\n",
    "# add constant to tensor\n",
    "c = torch.add(torch.tensor([0, 1]), 10)\n",
    "\n",
    "# multiply constant to tensor\n",
    "d = torch.mul(torch.tensor([0, 1]), 10)\n",
    "\n",
    "# trig functions, sin, cos, tan, etc...\n",
    "e = torch.sin(torch.tensor([45.]))\n",
    "f = torch.cos(torch.tensor([45.]))\n",
    "g = torch.tan(torch.tensor([45.]))\n",
    "h = torch.asin(torch.tensor([.4]))\n",
    "i = torch.acos(torch.tensor([.4]))\n",
    "j = torch.atan(torch.tensor([.4]))\n",
    "k = torch.atan2(torch.tensor([.4]), torch.tensor([.4]))\n",
    "\n",
    "# bitwise not \n",
    "l = torch.bitwise_not(torch.tensor([-1, -2, 4]))\n",
    "\n",
    "# rounding\n",
    "m = torch.ceil(torch.tensor([-0.5, -1.2, 1.2, 0.5]))\n",
    "n = torch.floor(torch.tensor([-0.5, -1.2, 1.2, 0.5]))\n",
    "\n",
    "# restricting values\n",
    "o = torch.clamp(\n",
    "    torch.tensor([-8., -0.3, 0.0, 0.3, 8.]), \n",
    "    min=-0.5, max=0.5)\n",
    "\n",
    "# exponentiation\n",
    "p = torch.exp(torch.tensor([2.0]))\n",
    "\n",
    "# modulus and remainder\n",
    "q = torch.fmod(torch.tensor([-2, -1, 1, 2]), 2)\n",
    "r = torch.remainder(torch.tensor([-2, -1, 1, 2]), 2)\n",
    "\n",
    "# log\n",
    "s = torch.log(torch.tensor([1., 2., 2.]))\n",
    "\n",
    "# logical not anx XOR\n",
    "t = torch.logical_not(torch.tensor([True, False]))\n",
    "u = torch.logical_xor(\n",
    "    torch.tensor([True, False, True]), \n",
    "    torch.tensor([True, False, False]))\n",
    "\n",
    "# negative\n",
    "v = torch.neg(torch.tensor([-1, -2]))\n",
    "\n",
    "# power\n",
    "w = torch.pow(torch.tensor([1., 2., 3.]), 2)\n",
    "\n",
    "# reciprocal\n",
    "x = torch.reciprocal(torch.tensor([1., 2., 3.]))\n",
    "\n",
    "# sigmoid\n",
    "y = torch.sigmoid(torch.randn(4))\n",
    "\n",
    "# get the sign\n",
    "z = torch.sign(torch.tensor([-0.5, 0.5]))\n",
    "\n",
    "results = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z]\n",
    "for c, r in zip(list('abcdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: -2.0\n",
      "b: 1.0\n",
      "c: 3\n",
      "d: 2\n",
      "e: -1.0\n",
      "f: 2.0\n",
      "g: tensor([-1.,  0., -2., -1.])\n",
      "h: tensor([-1., -1.,  2.,  2.])\n",
      "i: 1.4142135381698608\n",
      "j: 1.4401897192001343\n",
      "k: -0.5\n",
      "l: -1.0\n",
      "m: torch.return_types.mode(\n",
      "values=tensor(1.),\n",
      "indices=tensor(3))\n",
      "n: 1.5\n",
      "o: (tensor(1.5000), tensor(-0.2500))\n",
      "p: 2.25\n",
      "q: (tensor(2.2500), tensor(-0.2500))\n",
      "r: tensor([-2., -1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "# min and max\n",
    "a = torch.tensor([-1., 0, -2., 1]).min()\n",
    "b = torch.tensor([-1., 0, -2., 1]).max()\n",
    "\n",
    "# argument (index) min and max\n",
    "c = torch.tensor([-1., 0, -2., 1]).argmax()\n",
    "d = torch.tensor([-1., 0, -2., 1]).argmin()\n",
    "\n",
    "# sum and product of elements\n",
    "e = torch.sum(torch.tensor([-1., 1, -2., 1]))\n",
    "f = torch.prod(torch.tensor([-1., 1, -2., 1]))\n",
    "\n",
    "# cummulative sum and product\n",
    "g = torch.cumsum(torch.tensor([-1., 1, -2., 1]), dim=0)\n",
    "h = torch.cumprod(torch.tensor([-1., 1, -2., 1]), dim=0)\n",
    "\n",
    "# p-norm distance between 2 tensors\n",
    "i = torch.dist(torch.tensor([0., 0.]), torch.tensor([1., 1.]), p=2)\n",
    "\n",
    "# log of sum of exponentiations\n",
    "j = torch.logsumexp(torch.tensor([-1., 0, -2., 1]), dim=0)\n",
    "\n",
    "# mean, median, mode, variance, standard deviaion\n",
    "k = torch.mean(torch.tensor([-1., 0, -2., 1]), dim=0)\n",
    "l = torch.median(torch.tensor([-1., 0, -2., 1]))\n",
    "m = torch.mode(torch.tensor([-1., 1, -2., 1]))\n",
    "n = torch.std(torch.tensor([-1., 1, -2., 1]))\n",
    "o = torch.std_mean(torch.tensor([-1., 1, -2., 1]))\n",
    "p = torch.var(torch.tensor([-1., 1, -2., 1]))\n",
    "q = torch.var_mean(torch.tensor([-1., 1, -2., 1]))\n",
    "\n",
    "# unique\n",
    "r = torch.unique(torch.tensor([-1., 1, -2., 1]))\n",
    "\n",
    "results = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r]\n",
    "for c, r in zip(list('abcdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: True\n",
      "b: tensor([5, 4, 3, 2, 1, 0, 6])\n",
      "c: tensor([True, True])\n",
      "d: True\n",
      "e: True\n",
      "f: tensor([False, False])\n",
      "g: tensor([False, False])\n",
      "h: tensor([True, True])\n",
      "i: tensor([True, True])\n",
      "j: tensor([ True, False, False, False])\n",
      "k: tensor([False,  True,  True, False])\n",
      "l: tensor([False, False, False,  True])\n",
      "m: torch.return_types.kthvalue(\n",
      "values=tensor([-1, -1]),\n",
      "indices=tensor([0, 1]))\n",
      "n: torch.return_types.topk(\n",
      "values=tensor([[0, 0]]),\n",
      "indices=tensor([[1, 0]]))\n",
      "o: -1\n",
      "p: 10\n",
      "q: torch.return_types.sort(\n",
      "values=tensor([[ 8,  9, 10]]),\n",
      "indices=tensor([[2, 1, 0]]))\n"
     ]
    }
   ],
   "source": [
    "# are elements pretty close?\n",
    "a = torch.allclose(\n",
    "    torch.tensor([1.09, 2.08, float('nan')]), \n",
    "    torch.tensor([1.08, 2.07, float('nan')]), \n",
    "    rtol=1e-02, equal_nan=True)\n",
    "\n",
    "# sort the indices according to corresponding values\n",
    "b = torch.argsort(torch.tensor([5., 3., 1., -1., -3., -5., 6]))\n",
    "\n",
    "# element-wise equality\n",
    "c = torch.eq(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "\n",
    "# are tensors equal by dimensions\n",
    "d = torch.equal(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "\n",
    "# are tensors equal by dimensions\n",
    "e = torch.equal(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "\n",
    "# equality, >, <, >=, <=\n",
    "f = torch.gt(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "g = torch.lt(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "h = torch.ge(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "i = torch.le(torch.tensor([1., 2.]), torch.tensor([1., 2.]))\n",
    "\n",
    "# check if each element is finite, infinity\n",
    "j = torch.isfinite(\n",
    "    torch.tensor([1, float('inf'), float('-inf'), float('nan')]))\n",
    "k = torch.isinf(\n",
    "    torch.tensor([1, float('inf'), float('-inf'), float('nan')]))\n",
    "l = torch.isnan(\n",
    "    torch.tensor([1, float('inf'), float('-inf'), float('nan')]))\n",
    "\n",
    "# finds k smallest numbers, # finds k largest numbers\n",
    "m = torch.kthvalue(torch.tensor([[-1, 0], [0, -1]]), k=1, dim=0)\n",
    "n = torch.topk(torch.tensor([[-1, 0], [0, -1]]), k=1, dim=0)\n",
    "\n",
    "# finds min/max\n",
    "o = torch.min(torch.tensor([5, -1, 10]))\n",
    "p = torch.max(torch.tensor([5, -1, 10]))\n",
    "\n",
    "# sorting\n",
    "q = torch.sort(torch.tensor([[10, 9, 8]]))\n",
    "\n",
    "results = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q]\n",
    "for c, r in zip(list('abcdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tensor([3., 5.])\n",
      "d: tensor([-1., -1.])\n",
      "e: tensor([2., 6.])\n",
      "f: tensor([0.5000, 0.6667])\n",
      "g: 8.0\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1., 2.])\n",
    "b = torch.tensor([2., 3.])\n",
    "\n",
    "c = a + b\n",
    "d = a - b\n",
    "e = a * b\n",
    "f = a / b\n",
    "g = a.dot(b)\n",
    "\n",
    "results = [c,d,e,f,g]\n",
    "for c, r in zip(list('cdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "d: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "e: tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "f: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "g: tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n",
      "h: tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n",
      "i: 2\n",
      "j: (tensor([[3.0000, 4.0000],\n",
      "        [0.3333, 0.6667]]), tensor([2, 2], dtype=torch.int32))\n",
      "k: -1.9999998807907104\n",
      "l: tensor([[-2.0000,  1.0000],\n",
      "        [ 1.5000, -0.5000]])\n",
      "m: tensor([20., 46.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float)\n",
    "b = torch.tensor([[1, 2], [3, 4]], dtype=torch.float)\n",
    "\n",
    "c = a + b\n",
    "d = a - b\n",
    "e = a * b\n",
    "f = a / b\n",
    "g = torch.matmul(a, b)\n",
    "h = torch.matrix_power(a, 2)\n",
    "i = torch.matrix_rank(a)\n",
    "j = torch.lu(a)\n",
    "k = torch.det(a)\n",
    "l = torch.inverse(a)\n",
    "m = torch.mv(a, torch.tensor([6., 7.]))\n",
    "\n",
    "results = [c,d,e,f,g,h,i,j,k,l,m]\n",
    "for c, r in zip(list('cdefghijklmnopqrstuvwxyz'), results):\n",
    "    print(f'{c}: {r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Two tensors are `broadcastable` if\n",
    "\n",
    "* each tensor has at least one dimension, and\n",
    "* from the trailing dimension to the leadng one, the dimensions are\n",
    "  * equal,\n",
    "  * one of them is 1, or\n",
    "  * one of them does not exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be broadcasted\n",
    "a = torch.empty(5, 7, 3)\n",
    "b = torch.empty(5, 7, 3)\n",
    "\n",
    "# cannot be broadcasted\n",
    "a = torch.empty((0,))\n",
    "b = torch.empty(2, 2)\n",
    "\n",
    "# can line up trailing dimensions\n",
    "a = torch.empty(5,3,4,1)\n",
    "b = torch.empty(  3,1,1)\n",
    "\n",
    "# cannot be broadcasted\n",
    "a = torch.empty(5,2,4,1)\n",
    "b = torch.empty(  3,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device-agnostic tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n",
      "tensor(10, device='cuda:0')\n",
      "tensor([0.0472, 0.9254], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'device = {device}')\n",
    "\n",
    "a = torch.tensor(10, device=device)\n",
    "b = torch.rand(2, device=device)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may move the tensors between devices (CPU or GPU) as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor(10, device='cuda:0')\n",
      "b tensor(10)\n",
      "c tensor(10)\n",
      "d tensor(10)\n",
      "e tensor(10, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# a is on the GPU\n",
    "a = torch.tensor(10, device='cuda:0')\n",
    "# b is on the CPU\n",
    "b = torch.tensor(10, device='cpu')\n",
    "\n",
    "# move a to the CPU is possible in two ways\n",
    "c = a.cpu()\n",
    "d = a.to('cpu')\n",
    "\n",
    "# move b to the GPU is as follows\n",
    "e = b.to('cuda:0')\n",
    "\n",
    "print('a', a)\n",
    "print('b', b)\n",
    "print('c', c)\n",
    "print('d', d)\n",
    "print('e', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0, 1, 2, 3])\n",
    "torch.save(a, './output/mytensor.pt')\n",
    "\n",
    "b = torch.load('./output/mytensor.pt')\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
