{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01/05 | TRAIN: 1.1829, 0.6667, 0m 1s | TEST: 2.1690, 0.4000, 0m 0s\n",
      "epoch 02/05 | TRAIN: 0.8402, 0.8000, 0m 1s | TEST: 0.0073, 1.0000, 0m 0s\n",
      "epoch 03/05 | TRAIN: 0.7039, 0.8667, 0m 1s | TEST: 0.0217, 1.0000, 0m 0s\n",
      "epoch 04/05 | TRAIN: 0.2520, 0.8667, 0m 1s | TEST: 0.0139, 1.0000, 0m 0s\n",
      "epoch 05/05 | TRAIN: 0.4865, 0.8667, 0m 1s | TEST: 0.0039, 1.0000, 0m 0s\n",
      "completed learning in 0m 5s, best accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def train(dataloaders, model, criterion, optimizer, scheduler, device, num_epochs=20):\n",
    "    def format_start_stop(start, stop):\n",
    "        elapsed = stop - start\n",
    "        return f'{elapsed//60:.0f}m {elapsed%50:.0f}s'\n",
    "    \n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = -1.0\n",
    "    \n",
    "    loop_start = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        test_loss, test_acc = 0.0, 0.0\n",
    "        train_start, test_start = 0.0, 0.0\n",
    "        train_stop, test_stop = 0.0, 0.0\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "                train_start = time.time()\n",
    "            else:\n",
    "                model.eval()\n",
    "                test_start = time.time()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            n = 0\n",
    "            dataloader = dataloaders[phase]\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.mean() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                n += len(labels)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "            epoch_acc = running_corrects.double() / float(n)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_stop = time.time()\n",
    "                train_loss, train_acc = epoch_loss, epoch_acc\n",
    "            else:\n",
    "                test_stop = time.time()\n",
    "                test_loss, test_acc = epoch_loss, epoch_acc\n",
    "                \n",
    "                if epoch_acc > best_acc:\n",
    "                    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                    best_acc = epoch_acc                \n",
    "        \n",
    "        train_time = format_start_stop(train_start, train_stop)\n",
    "        test_time = format_start_stop(test_start, test_stop)\n",
    "        \n",
    "        train_metrics = f'TRAIN: {train_loss:.4f}, {train_acc:.4f}, {train_time}'\n",
    "        test_metrics = f'TEST: {test_loss:.4f}, {test_acc:.4f}, {test_time}'\n",
    "        print(f'epoch {str(epoch + 1).zfill(2)}/{str(num_epochs).zfill(2)} | {train_metrics} | {test_metrics}')\n",
    "    \n",
    "    loop_stop = time.time()\n",
    "    loop_time = format_start_stop(loop_start, loop_stop)\n",
    "    print(f'completed learning in {loop_time}, best accuracy {best_acc:.4f}')\n",
    "    \n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model\n",
    "\n",
    "def get_dataloaders():\n",
    "    def clean_up(path):\n",
    "        import os\n",
    "        from shutil import rmtree\n",
    "        \n",
    "        ipynb_checkpoints = f'{path}/.ipynb_checkpoints'\n",
    "        if os.path.exists(ipynb_checkpoints):\n",
    "            rmtree(ipynb_checkpoints)\n",
    "            \n",
    "    def get_dataloader(phase):\n",
    "        path = f'./shapes/{phase}'\n",
    "        clean_up(path)\n",
    "        \n",
    "        transform = transforms.Compose([Resize(224), ToTensor()])\n",
    "        image_folder = datasets.ImageFolder(path, transform=transform)\n",
    "        # print(path, image_folder.classes)\n",
    "        return DataLoader(image_folder, batch_size=4, shuffle=True, num_workers=4)\n",
    "    \n",
    "    return {phase: get_dataloader(phase) for phase in ['train', 'test', 'valid']}\n",
    "\n",
    "np.random.seed(37)\n",
    "torch.manual_seed(37)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "pretrained=True\n",
    "num_classes = 3\n",
    "num_epochs = 5\n",
    "\n",
    "dataloaders = get_dataloaders()\n",
    "\n",
    "model = models.resnet18(pretrained=pretrained)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Rprop(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "model = train(dataloaders, model, criterion, optimizer, scheduler, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    results = []\n",
    "    truths = []\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            probs = F.softmax(outputs, dim=1).cpu().detach().numpy()\n",
    "            \n",
    "            truths.append(labels.cpu().detach().numpy())\n",
    "            results.append(probs)\n",
    "    return np.vstack(results), np.hstack(truths)\n",
    "            \n",
    "P, y = validate(model, dataloaders['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.09239802e-04, 9.98647034e-01, 1.24368677e-03],\n",
       "       [9.99996543e-01, 4.27103942e-07, 3.02703666e-06],\n",
       "       [8.24902789e-04, 9.94648993e-01, 4.52606427e-03],\n",
       "       [3.14544668e-05, 9.99468505e-01, 5.00007591e-04],\n",
       "       [1.00000000e+00, 1.89986444e-08, 3.60023762e-08],\n",
       "       [6.85336943e-08, 3.33887947e-05, 9.99966502e-01],\n",
       "       [2.31350423e-05, 9.99559224e-01, 4.17684234e-04],\n",
       "       [9.99996662e-01, 2.38815005e-06, 9.01562430e-07],\n",
       "       [7.80323899e-06, 1.05366234e-04, 9.99886870e-01],\n",
       "       [6.09260278e-05, 9.24190972e-04, 9.99014854e-01],\n",
       "       [7.34221772e-04, 9.94967997e-01, 4.29777801e-03],\n",
       "       [9.99832392e-01, 1.10261331e-04, 5.72778845e-05],\n",
       "       [5.12135259e-08, 3.99566670e-06, 9.99995947e-01],\n",
       "       [9.99997616e-01, 6.17816795e-07, 1.76223170e-06],\n",
       "       [3.50799993e-08, 5.10070663e-07, 9.99999523e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve([1 if label == i else 0 for label in y], P[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "y_test = np.array([[1 if label == i else 0 for label in y] for i in range(num_classes)]).ravel()\n",
    "y_preds = P.ravel()\n",
    "fpr['micro'], tpr['micro'], _ = roc_curve(y_test, y_preds)\n",
    "roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(num_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= num_classes\n",
    "\n",
    "fpr['macro'], tpr['macro'] = all_fpr, mean_tpr\n",
    "roc_auc['macro'] = auc(fpr['macro'], tpr['macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0, 2: 1.0, 'micro': 0.54, 'macro': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09239802e-04, 9.98647034e-01, 1.24368677e-03, 9.99996543e-01,\n",
       "       4.27103942e-07, 3.02703666e-06, 8.24902789e-04, 9.94648993e-01,\n",
       "       4.52606427e-03, 3.14544668e-05, 9.99468505e-01, 5.00007591e-04,\n",
       "       1.00000000e+00, 1.89986444e-08, 3.60023762e-08, 6.85336943e-08,\n",
       "       3.33887947e-05, 9.99966502e-01, 2.31350423e-05, 9.99559224e-01,\n",
       "       4.17684234e-04, 9.99996662e-01, 2.38815005e-06, 9.01562430e-07,\n",
       "       7.80323899e-06, 1.05366234e-04, 9.99886870e-01, 6.09260278e-05,\n",
       "       9.24190972e-04, 9.99014854e-01, 7.34221772e-04, 9.94967997e-01,\n",
       "       4.29777801e-03, 9.99832392e-01, 1.10261331e-04, 5.72778845e-05,\n",
       "       5.12135259e-08, 3.99566670e-06, 9.99995947e-01, 9.99997616e-01,\n",
       "       6.17816795e-07, 1.76223170e-06, 3.50799993e-08, 5.10070663e-07,\n",
       "       9.99999523e-01], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
