{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference in Gaussian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [junction tree algorithm](https://en.wikipedia.org/wiki/Junction_tree_algorithm) (`JTA`) is a widely used algorithm for exact inference in Bayesian Belief Networks (`BBNs`). A great paper to learn the mechanics of JTA is authored by [Huang and Darwiche](http://pages.cs.wisc.edu/~dpage/ijar95.pdf). The Huang and Darwiche paper focuses only on discrete variables and leaves a lot to be desired if one has continuous variables. \n",
    "\n",
    "The JTA may also be applied to continuous variables, and in particular, a set of Gaussian variables (multivariate Gaussian). The key idea in JTA is to transform a directed acylic graph (`DAG`) into a junction tree (`JT`). Once a JT is created, probabilistic inference to extract marginal probabilities (with or without evidence) is possible. Just like a BBN, which is composed of a graph (structure), `G`, and joint probability (parameters), `P`, a JT also has this type of duality. The graph of a JT is composed of nodes (`cliques` and `separation sets`) and edges (structure), and associated with each node is a `potential` (parameters). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potentials, discrete variables\n",
    "\n",
    "Potentials are the key to `inference` in JTA. Inference is conducted in JTA by passing `messages` (potentials) around. The representation of potentials is one of the two key differences between using JTA for discrete versus continuous variables (the other being how evidence is injected into the JT). For JTA with discrete variables, a potential is essentially a table. Below, we have a clique associated with the binary variables `A` and `B`. The potential associated with this clique would be the cross-product of the domains and a value (typically between $[0, 1]$) associated to each combination of the instantiations. \n",
    "\n",
    "<pre>\n",
    "| A   | B   | value |\n",
    "|-----|-----|-------|\n",
    "| on  | on  | 0.2   |\n",
    "| on  | off | 0.3   |\n",
    "| off | on  | 0.4   |\n",
    "| off | off | 0.8   |\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potentials, Gaussian variables\n",
    "\n",
    "The representation of potentials in a JT for Gaussian variables is entirely different. Let's look at the density function of a multivariate Gaussian.\n",
    "\n",
    "$f_X(x_1, x_2, \\ldots, x_n)=\\cfrac{\\exp\\left(\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)}{2\\pi^{n/2}|\\Sigma|^{\\frac{1}{2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
