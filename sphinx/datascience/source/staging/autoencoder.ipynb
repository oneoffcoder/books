{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-marina",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-monday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retired-working",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:26:39.926514Z",
     "iopub.status.busy": "2022-01-02T05:26:39.926330Z",
     "iopub.status.idle": "2022-01-02T05:26:42.385351Z",
     "shell.execute_reply": "2022-01-02T05:26:42.384864Z",
     "shell.execute_reply.started": "2022-01-02T05:26:39.926459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([-0.0545], device='cuda:0', dtype=torch.float64)\n",
      "1 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([0.6743], device='cuda:0', dtype=torch.float64)\n",
      "2 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([0.3466], device='cuda:0', dtype=torch.float64)\n",
      "3 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([-1.3003], device='cuda:0', dtype=torch.float64)\n",
      "4 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([1.5185], device='cuda:0', dtype=torch.float64)\n",
      "5 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([0.9898], device='cuda:0', dtype=torch.float64)\n",
      "6 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([0.2777], device='cuda:0', dtype=torch.float64)\n",
      "7 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([-0.4486], device='cuda:0', dtype=torch.float64)\n",
      "8 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([0.9620], device='cuda:0', dtype=torch.float64)\n",
      "9 <class 'tuple'> <class 'torch.Tensor'> <class 'int'> 0 tensor([-0.8276], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import *\n",
    "\n",
    "np.random.seed(37)\n",
    "rand.seed(37)\n",
    "\n",
    "class GaussianDataset(Dataset):\n",
    "    def __init__(self, device, loc=0, scale=1, clazz=0, N=1_000):\n",
    "        self.__device = device\n",
    "        self.__clazz = clazz\n",
    "        self.__X = np.random.normal(loc=loc, scale=scale, size=N).reshape(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.__X[idx,:]\n",
    "        item = torch.tensor(item, device=self.__device).double()\n",
    "        \n",
    "        return item, self.__clazz\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "dataset = GaussianDataset(device=device)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, type(dataset[i]),\n",
    "          type(dataset[i][0]),\n",
    "          type(dataset[i][1]),\n",
    "          dataset[i][1],\n",
    "          dataset[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "armed-morning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:26:42.386189Z",
     "iopub.status.busy": "2022-01-02T05:26:42.386059Z",
     "iopub.status.idle": "2022-01-02T05:26:42.390651Z",
     "shell.execute_reply": "2022-01-02T05:26:42.390156Z",
     "shell.execute_reply.started": "2022-01-02T05:26:42.386174Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "          \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)\n",
    "        )\n",
    "          \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, input_size)\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saved-haiti",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:26:42.394248Z",
     "iopub.status.busy": "2022-01-02T05:26:42.394077Z",
     "iopub.status.idle": "2022-01-02T05:26:42.428038Z",
     "shell.execute_reply": "2022-01-02T05:26:42.427532Z",
     "shell.execute_reply.started": "2022-01-02T05:26:42.394226Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AE(input_size=1).double().to(device)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-moore",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:26:42.429000Z",
     "iopub.status.busy": "2022-01-02T05:26:42.428761Z",
     "iopub.status.idle": "2022-01-02T05:27:30.471123Z",
     "shell.execute_reply": "2022-01-02T05:27:30.470717Z",
     "shell.execute_reply.started": "2022-01-02T05:26:42.428933Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "outputs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    \n",
    "    for (item, _) in dataset:  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstructed = model(item)\n",
    "        loss = loss_function(reconstructed, item)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy().item())\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    \n",
    "    outputs.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'loss': losses.mean()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faced-french",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:27:30.471723Z",
     "iopub.status.busy": "2022-01-02T05:27:30.471623Z",
     "iopub.status.idle": "2022-01-02T05:27:30.478145Z",
     "shell.execute_reply": "2022-01-02T05:27:30.477849Z",
     "shell.execute_reply.started": "2022-01-02T05:27:30.471710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 0, 'loss': 0.09523458393174913},\n",
       " {'epoch': 1, 'loss': 0.018831867539226145},\n",
       " {'epoch': 2, 'loss': 0.0003579292241994011},\n",
       " {'epoch': 3, 'loss': 0.02285746374549311},\n",
       " {'epoch': 4, 'loss': 0.002193471568789237},\n",
       " {'epoch': 5, 'loss': 0.006369732873779139},\n",
       " {'epoch': 6, 'loss': 0.006959465555705261},\n",
       " {'epoch': 7, 'loss': 0.0054271628551490194},\n",
       " {'epoch': 8, 'loss': 0.005842258403331565},\n",
       " {'epoch': 9, 'loss': 0.007888257921544838},\n",
       " {'epoch': 10, 'loss': 0.004061566742882887},\n",
       " {'epoch': 11, 'loss': 0.004239698714537946},\n",
       " {'epoch': 12, 'loss': 0.004314447164598894},\n",
       " {'epoch': 13, 'loss': 0.0031328218710224604},\n",
       " {'epoch': 14, 'loss': 0.007189506953647517},\n",
       " {'epoch': 15, 'loss': 0.003018659323039308},\n",
       " {'epoch': 16, 'loss': 0.005159008403002595},\n",
       " {'epoch': 17, 'loss': 0.002787532322056358},\n",
       " {'epoch': 18, 'loss': 0.0025876928968187867},\n",
       " {'epoch': 19, 'loss': 0.0018173679436896616}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cheap-equation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:27:30.478756Z",
     "iopub.status.busy": "2022-01-02T05:27:30.478651Z",
     "iopub.status.idle": "2022-01-02T05:27:30.502089Z",
     "shell.execute_reply": "2022-01-02T05:27:30.501746Z",
     "shell.execute_reply.started": "2022-01-02T05:27:30.478743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0545], dtype=torch.float64) tensor([-0.0707], dtype=torch.float64)\n",
      "tensor([0.6743], dtype=torch.float64) tensor([0.6595], dtype=torch.float64)\n",
      "tensor([0.3466], dtype=torch.float64) tensor([0.3325], dtype=torch.float64)\n",
      "tensor([-1.3003], dtype=torch.float64) tensor([-1.3089], dtype=torch.float64)\n",
      "tensor([1.5185], dtype=torch.float64) tensor([1.5454], dtype=torch.float64)\n",
      "tensor([0.9898], dtype=torch.float64) tensor([1.0038], dtype=torch.float64)\n",
      "tensor([0.2777], dtype=torch.float64) tensor([0.2649], dtype=torch.float64)\n",
      "tensor([-0.4486], dtype=torch.float64) tensor([-0.4463], dtype=torch.float64)\n",
      "tensor([0.9620], dtype=torch.float64) tensor([0.9731], dtype=torch.float64)\n",
      "tensor([-0.8276], dtype=torch.float64) tensor([-0.8340], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for r in range(10):\n",
    "    print(dataset[r][0].cpu(), model(dataset[r][0]).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "living-pencil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T05:27:30.502870Z",
     "iopub.status.busy": "2022-01-02T05:27:30.502723Z",
     "iopub.status.idle": "2022-01-02T05:27:30.505643Z",
     "shell.execute_reply": "2022-01-02T05:27:30.505325Z",
     "shell.execute_reply.started": "2022-01-02T05:27:30.502843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([-0.0545], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for item, _ in dataset:\n",
    "    print(item.shape)\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-treat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
