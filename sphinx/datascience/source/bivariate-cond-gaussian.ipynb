{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Conditional Gaussians\n",
    "\n",
    "Let's learn how to evaluate bivariate conditional gaussian distributions based on data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate\n",
    "\n",
    "For two gaussian variables, $X_1$ and $X_2$, the probability of $X_1$ given $X_2$ is defined as follows.\n",
    "\n",
    "$P(X_1|X_2=a) \\sim \\mathcal{N}\\left( \\mu_1 + \\dfrac{\\sigma_1}{\\sigma_2}\\rho(a - \\mu_2), (1 - \\rho^2)\\sigma_1^2 \\right)$,\n",
    "\n",
    "where\n",
    "\n",
    "* $\\mu_1$ is the mean of $X_1$\n",
    "* $\\mu_2$ is the mean of $X_2$\n",
    "* $\\sigma_1$ is the standard deviation of $X_1$\n",
    "* $\\sigma_2$ is the standard deviation of $X_2$\n",
    "* $\\rho$ is the correlation between $X_1$ and $X_2$\n",
    "\n",
    "A couple of things to note here.\n",
    "\n",
    "* $P(X_1|X_2=a)$ is drawn from a univariate normal distribution\n",
    "* Notice the $X_2=a$ part? This means that every probability evaluation of $X_1=b$ will considered at $X_2=a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "Let's simulate two variables $X$ and $Y$.\n",
    "\n",
    "* $X \\sim \\mathcal{N}(1, 1)$\n",
    "* $Y \\sim \\mathcal{N}(1 + 3.5 \\times X, 1)$\n",
    "\n",
    "Note that $Y$ is dependent on $X$, but, $X$ is not dependent on $Y$. The dependency of $Y$ on $X$ implies $P(Y|X) > P(X|Y)$ (the probability of $Y$ given $X$ should be greater than the probability of $X$ given $Y$). This implication has use for `causality` since there is `asymmetry`; $P(Y|X) \\neq P(X|Y)$. Of course, we can manipulate the dependency and distributions so that $P(Y|X) = P(X|Y)$, but, in real life, such relationships are rather rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means\n",
      "[1.01277839 4.52863965]\n",
      "\n",
      "mins\n",
      "[-2.31079823 -8.33142158]\n",
      "\n",
      "maxs\n",
      "[ 3.92919388 17.57679341]\n",
      "\n",
      "stddev matrix\n",
      "[[0.98156075 1.8353206 ]\n",
      " [1.8353206  3.5714234 ]]\n",
      "\n",
      "correlation matrix\n",
      "[[1.        0.9608716]\n",
      " [0.9608716 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "x = np.random.normal(1, 1, N)\n",
    "y = np.random.normal(1 + 3.5 * x, 1, N)\n",
    "\n",
    "data = np.vstack([x, y]).T\n",
    "means = data.mean(axis=0)\n",
    "mins = data.min(axis=0)\n",
    "maxs = data.max(axis=0)\n",
    "cov = np.cov(data.T)\n",
    "std = np.sqrt(cov)\n",
    "cor = np.corrcoef(data.T)\n",
    "\n",
    "print('means')\n",
    "print(means)\n",
    "print('')\n",
    "print('mins')\n",
    "print(mins)\n",
    "print('')\n",
    "print('maxs')\n",
    "print(maxs)\n",
    "print('')\n",
    "print('stddev matrix')\n",
    "print(std)\n",
    "print('')\n",
    "print('correlation matrix')\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling conditional normal gaussian\n",
    "\n",
    "After we simulate the data, we can estimate the means, variances, standard deviations and correlations from the data. Then, we can build a model of the conditional normal gaussian. Below, we use a class to model the conditional normal gaussian, `CondNorm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "class CondNormal(object):\n",
    "    def __init__(self, m_1, m_2, s_1, s_2, p, zero=0.0000001):\n",
    "        self.m_1 = m_1\n",
    "        self.m_2 = m_2\n",
    "        self.s_1 = s_1\n",
    "        self.s_2 = s_2\n",
    "        self.p = p\n",
    "        self.zero = zero\n",
    "    \n",
    "    def pdf(self, a, b):\n",
    "        m = self.m_1 + (self.s_1 / self.s_2) * self.p * (a - self.m_2)\n",
    "        s = (1.0 - np.power(self.p, 2.0)) * np.power(self.s_1, 2.0)\n",
    "        p = norm.pdf(b, loc=m, scale=s)\n",
    "        p = np.log(p) if p >= self.zero else p\n",
    "        return p if pd.notna(p) else 0.0\n",
    "    \n",
    "    def empirical_log_proba(self, data):\n",
    "        return sum([self.pdf(a, b) for a, b in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following.\n",
    "\n",
    "* `p_x_y` is the model of $X | Y = a$ or $Y \\rightarrow X$, denoted $\\mathcal{N}_{X|Y}$\n",
    "* `p_y_x` is the model of $Y | X = a$ or $X \\rightarrow Y$, denoted $\\mathcal{N}_{Y|X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_y = CondNormal(means[0], means[1], \n",
    "                   std[0][0], std[1][1], cor[0][1])\n",
    "p_y_x = CondNormal(means[1], means[0], \n",
    "                   std[1][1], std[0][0], cor[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models\n",
    "\n",
    "Here, we evaluate the log probability of the data given the two models. Remeber Bayes' Theorem.\n",
    "\n",
    "$P(M|D) = \\dfrac{P(D|M)P(M)}{P(D)}$\n",
    "\n",
    "where\n",
    "\n",
    "* $M$ is the model (e.g. $\\mathcal{N}_{X|Y}$ and $\\mathcal{N}_{Y|X}$)\n",
    "* $D$ is the data\n",
    "\n",
    "$P(D)$ is the `normalizing constant` and drops out; $P(M)$ is assumed to be uniform and also drops out. Thus, the following.\n",
    "\n",
    "$P(M|D) \\propto P(D|M)$\n",
    "\n",
    "In theory, the `likelihood` is\n",
    "\n",
    "$P(D|M) = P(d_1|M) \\times P(d_2|M) \\times \\cdots \\times P(d_n|M)$\n",
    "\n",
    "In practice,\n",
    "\n",
    "$P(D|M) = P(d_1|M) \\times P(d_2|M) \\times \\cdots \\times P(d_n|M) \\propto \\sum \\log P(d_i|M)$\n",
    "\n",
    "where a higher score is better (all the scores will be negative since the log of $x \\in [0, 1]$ is $\\leq 0$).\n",
    "\n",
    "We see below that $P(D|\\mathcal{N}_{X|Y}) < P(D|\\mathcal{N}_{Y|X})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2262.259913305025"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_x_y.empirical_log_proba([(v[1], v[0]) for v in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1407.7504048724836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_x.empirical_log_proba([(v[0], v[1]) for v in data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
