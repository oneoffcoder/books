{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chernoff Faces, Classification\n",
    "\n",
    "In this notebook, we take the synthetic data generated from [chernoff-faces.ipynb](chernoff-faces.ipynb) and apply two common classification techniques (logistic regression and random forest) to classify the data. \n",
    "\n",
    "## Data\n",
    "\n",
    "We have to first load up the data. There are 2 data sets that we are acquring, the training `T` and validation `V` data sets. We will use `T` for learning and validate the model against `V` (which the model has not seen before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(37)\n",
    "\n",
    "tr_df = pd.read_csv('./faces/data-train.csv')\n",
    "va_df = pd.read_csv('./faces/data-valid.csv')\n",
    "\n",
    "Data = namedtuple('Data', 'X y')\n",
    "T = Data(tr_df[[i for i in tr_df.columns if i != 'y']], tr_df['y'])\n",
    "V = Data(va_df[[i for i in va_df.columns if i != 'y']], va_df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Metric = namedtuple('Metric', 'clazz tn fp fn tp sen spe acc f1 auc')\n",
    "\n",
    "def get_classification_metrics(model, T, V):\n",
    "    def get_metrics(clazz, cmatrix):\n",
    "        tn, fp, fn, tp = cmatrix[0][0], cmatrix[0][1], cmatrix[1][0], cmatrix[1][1]\n",
    "        sen = tp / (tp + fn)\n",
    "        spe = tn / (tn + fp)\n",
    "        acc = (tp + tn) / (tp + fp + fn + tn)\n",
    "        f1 = (2.0 * tp) / (2 * tp + fp + fn)\n",
    "        return clazz, tn, fp, fn, tp, sen, spe, acc, f1\n",
    "    \n",
    "    model.fit(T.X, T.y)\n",
    "    y_pred = model.predict(V.X)\n",
    "    cmatrices = multilabel_confusion_matrix(V.y, y_pred)\n",
    "    \n",
    "    try:\n",
    "        clazzes = sorted(list(T.y.value_counts().index))\n",
    "    except:\n",
    "        clazzes = np.unique(T.y).astype(int)\n",
    "        \n",
    "    y_pred = model.predict_proba(V.X)\n",
    "    metrics = []\n",
    "    for clazz in clazzes:\n",
    "        clazz, tn, fp, fn, tp, sen, spe, acc, f1 = get_metrics(clazz, cmatrices[clazz])\n",
    "        y_true = [1 if y == clazz else 0 for y in V.y]\n",
    "        auc = roc_auc_score(y_true, y_pred[:,clazz])\n",
    "        metric = Metric(clazz, tn, fp, fn, tp, sen, spe, acc, f1, auc)\n",
    "        metrics.append(metric)\n",
    "    return metrics\n",
    "        \n",
    "def print_classification_metrics(metrics):\n",
    "    for m in metrics:\n",
    "        print('{}: sen = {:.5f}, spe = {:.5f}, acc = {:.5f}, f1 = {:.5f}, auc = {:.5f}'\n",
    "              .format(m.clazz, m.sen, m.spe, m.acc, m.f1, m.auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "As you can see, logistic regression does not do so well for class 2 and 3 in terms of sensitivity. The problem might be due to data imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 0.82667, acc = 0.87000, f1 = 0.79365, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 0.74667, acc = 0.81000, f1 = 0.72464, auc = 1.00000\n",
      "2: sen = 0.72000, spe = 1.00000, acc = 0.93000, f1 = 0.83721, auc = 1.00000\n",
      "3: sen = 0.00000, spe = 1.00000, acc = 0.75000, f1 = 0.00000, auc = 0.66347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        LogisticRegression(random_state=37, multi_class='ovr', solver='newton-cg'), T, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "Random forest does well across all classification measures, even in the face of data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 0.98667, acc = 0.99000, f1 = 0.98039, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 0.88000, spe = 0.93333, acc = 0.92000, f1 = 0.84615, auc = 0.98107\n",
      "3: sen = 0.76000, spe = 0.96000, acc = 0.91000, f1 = 0.80851, auc = 0.96720\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        RandomForestClassifier(n_estimators=100, random_state=37), T, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data to counter data imbalance\n",
    "\n",
    "Let's see if we may combat data imbalance by learning the distribution per class, and then sampling new data from each of these new data. Note that we will learn from this new data set, not the original synthetic one. Furthermore, we will generate 10,000 new samples per class to make sure we get enough samples and also to combat data imbalance. We call this new data set `S` to distinguish it from `T`. Below, we will learn models from `S` and validate against `V`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 19)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def sample(mvn, N=10000):\n",
    "    X = np.array([multivariate_normal.rvs(mean=mvn.mean, cov=mvn.cov) for _ in range(N)])\n",
    "    y = np.full((N, 1), mvn.clazz, dtype=np.int32)\n",
    "    return np.hstack([X, y])\n",
    "\n",
    "Mvn = namedtuple('Mvn', 'clazz mean cov')\n",
    "\n",
    "X_cols = [i for i in tr_df.columns if i != 'y']\n",
    "\n",
    "mvns = { clazz: Mvn(clazz, \n",
    "                    tr_df[tr_df['y'] == clazz][X_cols].mean().values, \n",
    "                    tr_df[tr_df['y'] == clazz][X_cols].cov().values) \n",
    "        for clazz in list(sorted(tr_df['y'].value_counts().index)) }\n",
    "\n",
    "S = np.vstack([sample(mvn) for mvn in mvns.values()])\n",
    "print(S.shape)\n",
    "\n",
    "X = S[:, 0:S.shape[1] - 1]\n",
    "y = S[:, S.shape[1] - 1]\n",
    "\n",
    "S = Data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression applied to sampled data\n",
    "\n",
    "So, sampling does really help logistic regression. Look at the sensitivites for classes 2 and 3 go up (with class imbalance gone)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 0.88000, spe = 0.97333, acc = 0.95000, f1 = 0.89796, auc = 0.99467\n",
      "3: sen = 0.92000, spe = 0.96000, acc = 0.95000, f1 = 0.90196, auc = 0.99253\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        LogisticRegression(random_state=37, multi_class='ovr', solver='newton-cg'), S, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest applied to sampled data\n",
    "\n",
    "Random forest is also a beneficiary of sampling as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
      "2: sen = 0.96000, spe = 0.97333, acc = 0.97000, f1 = 0.94118, auc = 0.99787\n",
      "3: sen = 0.92000, spe = 0.98667, acc = 0.97000, f1 = 0.93878, auc = 0.99733\n"
     ]
    }
   ],
   "source": [
    "print_classification_metrics(\n",
    "    get_classification_metrics(\n",
    "        RandomForestClassifier(n_estimators=100, random_state=37), S, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classifications\n",
    "\n",
    "Now, let's compare and contrast the classification performances of the Inception V3 network against random forest.\n",
    "\n",
    "Inception V3 had the following validation results.\n",
    "\n",
    "```\n",
    "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, mcc = 1.00000\n",
    "1: sen = 1.00000, spe = 0.97333, acc = 0.98000, f1 = 0.96154, mcc = 0.94933\n",
    "2: sen = 0.80000, spe = 0.94667, acc = 0.91000, f1 = 0.81633, mcc = 0.75703\n",
    "3: sen = 0.76000, spe = 0.93333, acc = 0.89000, f1 = 0.77551, mcc = 0.70296\n",
    "```\n",
    "\n",
    "Random forest had the following validation results.\n",
    "\n",
    "```\n",
    "0: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
    "1: sen = 1.00000, spe = 1.00000, acc = 1.00000, f1 = 1.00000, auc = 1.00000\n",
    "2: sen = 0.96000, spe = 0.97333, acc = 0.97000, f1 = 0.94118, auc = 0.99787\n",
    "3: sen = 0.92000, spe = 0.98667, acc = 0.97000, f1 = 0.93878, auc = 0.99733\n",
    "```\n",
    "\n",
    "For classes 0 and 1, both techniques produced nearly identical results; not interesting since those classes were abundant relatively in the training data. However, the performances for classes 2 and 3 are where we see the biggest differences. Clearly, random forest does a whole lot better with the help of sampling. Inception V3 should also benefit from sampling, if there is a way to sample from the images (we pretend we do NOT know that the Chernoff faces came from multivariate, multi-level gaussian distributions). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
